{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\venvs\\sk_env2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qtpy.QtGui import QFont, QImage, QPixmap, QColor\n",
    "from qtpy.QtCore import Qt, Signal, QEvent, QTimer, QObject\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel\n",
    "from qtpy.QtWidgets import (QPushButton, \n",
    "                            QComboBox, \n",
    "                            QSlider, \n",
    "                            QTextEdit, \n",
    "                            QPlainTextEdit, \n",
    "                            QWidget, \n",
    "                            QVBoxLayout, \n",
    "                            QHBoxLayout,\n",
    "                            QLineEdit,\n",
    "                            QLabel,\n",
    "                            QFileDialog,     \n",
    "                            QCheckBox,     \n",
    "                            QDoubleSpinBox,\n",
    "                            QSpinBox,    \n",
    "                            QAbstractSpinBox,  \n",
    "                            QMainWindow, \n",
    "                            QTableWidgetItem,\n",
    "                            QTableWidget,    \n",
    "                            QApplication, \n",
    "                            QMainWindow,    \n",
    "                            QDialog,\n",
    "                            QScrollArea, \n",
    "                            QSizePolicy,\n",
    "                            QAbstractItemView                           \n",
    "                            )\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import sys\n",
    "import cv2\n",
    "import porespy  as ps\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254: 0\n",
      "256: 1024\n",
      "257: 1024\n",
      "258: 8\n",
      "262: 1\n",
      "270: ImageJ=1.53j\n",
      "images=120\n",
      "channels=4\n",
      "slices=30\n",
      "hyperstack=true\n",
      "mode=composite\n",
      "loop=false\n",
      "273: (3426,)\n",
      "277: 1\n",
      "278: 1024\n",
      "279: (1048576,)\n",
      "50838: (20, 64, 768, 768, 768, 768)\n",
      "50839: {'Ranges': (0.0, 255.0, 0.0, 255.0, 0.0, 255.0, 0.0, 255.0), 'LUTs': [array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8), array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8), array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255]], dtype=uint8), array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255],\n",
      "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
      "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
      "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
      "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
      "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
      "        247, 248, 249, 250, 251, 252, 253, 254, 255]], dtype=uint8)]}\n",
      "Image dim: [1, 30, 1024, 1024, 4]\n",
      "Strange dimension\n",
      "length 4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "(1, 30, 1024, 1024, 4)\n",
      "(1, 30, 1024, 1024, 4)\n",
      "shape: (1024, 1024, 4), type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "class ReadImage():\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        #Import image\n",
    "        \n",
    "        self.image_data = tiff.imread(path)\n",
    "\n",
    "        # Normalize - generate dimension list (T,Z,H,W,C)\n",
    "        self.dim = self.id_tiff_dim(path)\n",
    "        # Reshape - STANDARDIZED \n",
    "        self.image_data = ((self.image_data / np.max(self.image_data)) * 255).astype(np.uint8)\n",
    "\n",
    "        # IF shape: ZCXY ---------------------------------------------------------------\n",
    "        # Change to TZXYC\n",
    "        if self.image_data.shape[-3] <= 4:\n",
    "            \n",
    "            # dim = [1, 15, 1024, 1024, 3]\n",
    "            print(\"Strange dimension\")\n",
    "            #if no time step data \n",
    "            if len(self.image_data.shape) == 4: \n",
    "                print(f'length {len(self.image_data.shape)}')\n",
    "                self.image_data = self.image_data[np.newaxis,:,:,:,:]\n",
    "\n",
    "            # Create an empty array with the specified dimensions\n",
    "            image_data_stacked = np.empty(self.dim, dtype=np.uint8)\n",
    "\n",
    "            num_time_frames = self.dim[0]  # Get the number of time frames\n",
    "            \n",
    "            for t in range(num_time_frames):  # Iterate over the time frames\n",
    "                for i in range(self.dim[1]):  # Iterate over the images in each time frame\n",
    "                    # Get the red, green, and blue channels for the i-th image in the t-th time frame\n",
    "                    print(i)\n",
    "                    chan_0 = self.image_data[t, i, 0, :, :]  # Assuming the first dimension is time frame, then image index\n",
    "                    chan_1 = self.image_data[t, i, 1, :, :]\n",
    "                    chan_2 = self.image_data[t, i, 2, :, :]\n",
    "                    \n",
    "                    # Stack the channels along the last axis\n",
    "                    image_data_stacked[t, i, :, :, 0] = chan_0\n",
    "                    image_data_stacked[t, i, :, :, 1] = chan_1\n",
    "                    image_data_stacked[t, i, :, :, 2] = chan_2   \n",
    "                    # if have a an alpha channel\n",
    "                    if self.image_data.shape[2] >= 4:\n",
    "                        chan_3 = self.image_data[t, i, 3, :, :] \n",
    "                        image_data_stacked[t, i, :, :, 3] = chan_3 \n",
    "\n",
    "                    # if have a an alpha channel\n",
    "                    if self.image_data.shape[2] == 5:\n",
    "                        chan_4 = self.image_data[t, i, 4, :, :] \n",
    "                        image_data_stacked[t, i, :, :, 4] = chan_4 \n",
    "\n",
    "            print(image_data_stacked.shape)   \n",
    "\n",
    "            self.image_data = image_data_stacked \n",
    "            print(image_data_stacked.shape)\n",
    "            self.slice = self.image_data[0,9,:,:,:]\n",
    "            self.stack = self.image_data[0, :, :, :, :]\n",
    "            print(f'shape: {self.slice.shape}, type: {type(self.slice)}')\n",
    "        # ---------------------------------------------------------------------------------           \n",
    "        \n",
    "    def id_tiff_dim(self,f_path):\n",
    "        tif_file = tiff.TiffFile(f_path)\n",
    "        # Check for TIFF metadata tags\n",
    "        metadata = tif_file.pages[0].tags\n",
    "        if metadata:\n",
    "            # print(\"Metadata Tags:\")\n",
    "            for tag_name, tag in metadata.items():\n",
    "                print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "            #set dimension to 0 when a new tiff file is processed\n",
    "            dimension = [1,1,1,1,1] #dim, slices , time\n",
    "            \n",
    "            \n",
    "            #  T Z Y X C  (F, Z, H, W, C)\n",
    "            #  0 1 2 3 4\n",
    "            \n",
    "            if 256 in metadata: #width\n",
    "                            # Access the tag value directly\n",
    "                            dimension[3] = metadata[256].value\n",
    "            if 257 in metadata: #H\n",
    "                            # Access the tag value directly\n",
    "                            dimension[2] = metadata[257].value\n",
    "            if 277 in metadata: #channels\n",
    "                            # Access the tag value directly\n",
    "                            dimension[4] = metadata[277].value\n",
    "            if 259 in metadata:  # Tag for slices\n",
    "                            print(\"meta\",metadata[259].value)\n",
    "                            dimension[1] = metadata[259].value\n",
    "                        \n",
    "            if 'ImageDescription' in metadata:\n",
    "                    # Access 'ImageDescription' tag\n",
    "                    image_description = metadata['ImageDescription']\n",
    "            \n",
    "                    # Split the 'ImageDescription' string into lines\n",
    "                    description_lines = image_description.value.split('\\n')\n",
    "                    # Parse the lines to extract slices and frames information\n",
    "                    for line in description_lines:\n",
    "                        # if 262 in metadata:  # Tag for frames\n",
    "                        #     dimension[4] = metadata[262].value\n",
    "                        #     print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"slices=\"):\n",
    "                            dimension[1] = int(line.split('=')[1]) #slice\n",
    "                        if line.startswith(\"frames=\"):\n",
    "                            dimension[0] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"frames\", int(line.split('=')[1]))\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"channels=\"):\n",
    "                            dimension[4] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        \n",
    "        else:\n",
    "                print(\"ImageDescription tag not found in metadata.\")\n",
    "                        \n",
    "        # print(f'Width: {dimension[3]}')\n",
    "        # print(f'Height: {dimension[2]}')\n",
    "        # print(f'Channels: {dimension[4]}')\n",
    "        # print(f\"Slices: {dimension[1]}\")\n",
    "        # print(f\"Frames: {dimension[0]}\")\n",
    "        # print(f'Dimension: {dimension[0]}')\n",
    "        # self.dimension=dimension\n",
    "        # set_widg = [1,1]\n",
    "        # set_widg[0] = dimension[0] #t\n",
    "        # set_widg[1] = dimension[1] #z\n",
    "        # self.SIGNALS.reset_widget.emit(set_widg)\n",
    "        # self.SIGNALS.image_shape.emit(dimension)\n",
    "        # self.stack_dict[\"time_step\"]= 1\n",
    "        # self.zzval= round(set_widg[1]/2)\n",
    "        # if (dimension[0])==1 or (dimension[1])==1:\n",
    "        #     set_widg = [1,1]\n",
    "        #     self.SIGNALS.reset_widget.emit(set_widg)\n",
    "        #     self.stack_dict[\"time_step\"]=0\n",
    "        #     self.zzval=0\n",
    "        print(f'Image dim: {dimension}')\n",
    "        return dimension\n",
    "\n",
    "image_filepath = r\"C:\\Users\\dell\\Downloads\\Rapa+Baf_3\\Rapa+Baf_3.tif\"\n",
    "# image_filepath = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Control_2.tif\"\n",
    "# image_filepath = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\venvs\\sk_env2\\Lib\\site-packages\\ryven\\skripsie_projects\\batch_con\\Con 1 (20.3).tif\"\n",
    "read_img = ReadImage(image_filepath)\n",
    "# extract self.slice (object)\n",
    "# single slice (chose 1, 9, : , :, :)\n",
    "# slicexyx = read_img.slice\n",
    "# print(slicexyx.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "control_2_stack (15, 1024, 1024, 3)\n",
      "channel 1 stack: (15, 1024, 1024)\n",
      "channel 1 stack: (15, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "control_2_stack = read_img.stack\n",
    "print(\"control_2_stack\", control_2_stack.shape)\n",
    "chan_1_stack = control_2_stack[:,:,:,1]\n",
    "print(\"channel 1 stack:\", chan_1_stack.shape)\n",
    "chan_1_img_stack = chan_1_stack[:, :, :, np.newaxis]\n",
    "print(\"channel 1 stack:\", chan_1_img_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (1024, 1024, 1)\n",
      "1 (1024, 1024, 1)\n",
      "2 (1024, 1024, 1)\n",
      "3 (1024, 1024, 1)\n",
      "4 (1024, 1024, 1)\n",
      "5 (1024, 1024, 1)\n",
      "6 (1024, 1024, 1)\n",
      "7 (1024, 1024, 1)\n",
      "8 (1024, 1024, 1)\n",
      "9 (1024, 1024, 1)\n",
      "10 (1024, 1024, 1)\n",
      "11 (1024, 1024, 1)\n",
      "12 (1024, 1024, 1)\n",
      "13 (1024, 1024, 1)\n",
      "14 (1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "binaized_stack = []\n",
    "for i, stack in enumerate(chan_1_img_stack):\n",
    "    print(i, stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.cvtColor(control_2_stack[0, :,:,:], cv2.COLOR_BGR2GRAY)\n",
    "            #print(f\"SHAPE OF PROC {img.shape}\")    \n",
    "_, result = cv2.threshold(\n",
    "    src=img_gray,\n",
    "    thresh=100,\n",
    "    maxval=255,\n",
    "    type=cv2.THRESH_BINARY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 1024, 1024)\n",
      "(15, 1024, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, label, sum\n",
    "# img = read_img[0, 9, :, :, :]\n",
    "# print(img.shape)\n",
    "# Binarize image\n",
    "\n",
    "binarized_stack = np.zeros((15, 1024, 1024), dtype=np.uint8)\n",
    "\n",
    "for i in range(15):\n",
    "    img = control_2_stack[i,:,:,:]\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, result = cv2.threshold(\n",
    "        src=img_gray,\n",
    "        thresh=100,\n",
    "        maxval=255,\n",
    "        type=cv2.THRESH_BINARY,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    binarized_stack[i] = result\n",
    "\n",
    "print(binarized_stack.shape)\n",
    "binarisedImageStack = binarized_stack[:, :,:, np.newaxis]\n",
    "print(binarisedImageStack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial num labels: 464, num lables after filter: 64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, label, sum\n",
    "# img = read_img[0, 9, :, :, :]\n",
    "# print(img.shape)\n",
    "# Binarize image\n",
    "# binaized_stack = []\n",
    "# for i, stack in enumerate(chan_1_stack):\n",
    "#     img_gray = cv2.cvtColor(stack, cv2.COLOR_BGR2GRAY)\n",
    "#             #print(f\"SHAPE OF PROC {img.shape}\")    \n",
    "#     _, result = cv2.threshold(\n",
    "#         src=img_gray,\n",
    "#         thresh=100,\n",
    "#         maxval=255,\n",
    "#         type=cv2.THRESH_BINARY,\n",
    "#     )\n",
    "#     binaized_stack[i]=result\n",
    "    # binarisedImageStack = result[:, :, np.newaxis]\n",
    "\n",
    "# Assuming self.image_stack contains the binarized image stack\n",
    "# squeeze = np.squeeze(img_rehsape)\n",
    "# squeeze = squeeze.astype(int)  # Convert to int if not already\n",
    "\n",
    "# # Smooth the image using Gaussian filter (optional)\n",
    "# smoothed_image = gaussian_filter(squeeze, sigma=1)\n",
    "\n",
    "## Lable node ------------------------------------\n",
    "\n",
    "# Label connected components\n",
    "labeled, numpatches = label(binarisedImageStack)\n",
    "\n",
    "# Select min volume\n",
    "minVolume = 40\n",
    "\n",
    "# since labels start from 1 use this range\n",
    "sizes = sum(binarisedImageStack/np.max(binarisedImageStack), labeled, range(1, numpatches + 1))\n",
    "# print(np.sort(sizes.astype('uint32')))\n",
    "\n",
    "# to ensure \"black background\" is excluded add 1, and labels only start from 1\n",
    "filteredIndexes = np.where(sizes >= minVolume)[0] + 1\n",
    "\n",
    "filteredBinaryIndexes = np.zeros(numpatches + 1, np.uint8)\n",
    "filteredBinaryIndexes[filteredIndexes] = 1\n",
    "filteredBinary = filteredBinaryIndexes[labeled]\n",
    "\n",
    "labeledStack, numLabels = label(filteredBinary)\n",
    "print(\"Initial num labels: {}, num lables after filter: {}\".format(numpatches, numLabels))\n",
    "\n",
    "# sizes = ndimage.sum(filteredBinary/np.max(filteredBinary), labeledStack, range(1, numLabels + 1))\n",
    "# print(np.sort(sizes.astype('uint32')))\n",
    "\n",
    "# return filteredBinary, labeledStack, numLabels\n",
    "\n",
    "\n",
    "# ------------------------------------------------\n",
    "\n",
    "# # Selected value for structure size\n",
    "# selected_value = 1  # Number of pixels\n",
    "\n",
    "# # Initialize the count of structures\n",
    "# num_structures = 0\n",
    "\n",
    "# # Loop through each labeled region\n",
    "# # num_features represents the total number of unique labels in the image.\n",
    "# for label_id in range(1, num_features+1):\n",
    "#     # Calculate the area (number of pixels) of the current labeled region\n",
    "#     print(label_id, labeled)\n",
    "#     region_area = np.sum(labeled == label_id) # This comparison creates a boolean mask where True corresponds \n",
    "#                                               # to pixels belonging to the current labeled region (with label ID label_id) \n",
    "#                                               # and False otherwise. Sum these to find the size of the area. \n",
    "\n",
    "    \n",
    "#     # Check if the region's area is greater than the selected value\n",
    "#     if region_area >= selected_value:\n",
    "#         # Increment the count of structures\n",
    "#         num_structures += 1\n",
    "\n",
    "# print(\"Number of structures:\", num_structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 1024, 1024, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarisedImageStack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(binarisedImageStack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Timestep': 0, 'Total Structures': 464, 'Area Avg': 17.834051724137932, 'Centroid Avg': (5.073049734062022, 483.2219390034362, 419.8420927874811), 'Equivalent Diameter Avg': 2.4150695340725914, 'Euler Number Avg': 0.9612068965517241, 'Extent Avg': 0.7652916211166431, 'Filled Area Avg': 17.834051724137932, 'Inertia Tensor Eigenvalues Avg': (1.754462970240409, 1.2999550309352839, 0.6365924067206375), 'Volume Avg (Physical Space)': 17.834051724137932, 'Surface Area Avg (Physical Space)': 37.992821316266884, 'Sphericity Avg (Physical Space)': 0.8670581316534879, 'Aspect Ratio Avg (Major/Minor)': inf}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Total Structures</th>\n",
       "      <th>Area Avg</th>\n",
       "      <th>Centroid Avg</th>\n",
       "      <th>Equivalent Diameter Avg</th>\n",
       "      <th>Euler Number Avg</th>\n",
       "      <th>Extent Avg</th>\n",
       "      <th>Filled Area Avg</th>\n",
       "      <th>Inertia Tensor Eigenvalues Avg</th>\n",
       "      <th>Volume Avg (Physical Space)</th>\n",
       "      <th>Surface Area Avg (Physical Space)</th>\n",
       "      <th>Sphericity Avg (Physical Space)</th>\n",
       "      <th>Aspect Ratio Avg (Major/Minor)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>17.834052</td>\n",
       "      <td>5.073049734062022, 483.2219390034362, 419.8420...</td>\n",
       "      <td>2.41507</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.765292</td>\n",
       "      <td>17.834052</td>\n",
       "      <td>1.754462970240409, 1.2999550309352839, 0.63659...</td>\n",
       "      <td>17.834052</td>\n",
       "      <td>37.992821</td>\n",
       "      <td>0.867058</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestep  Total Structures   Area Avg  \\\n",
       "0         0               464  17.834052   \n",
       "\n",
       "                                        Centroid Avg  Equivalent Diameter Avg  \\\n",
       "0  5.073049734062022, 483.2219390034362, 419.8420...                  2.41507   \n",
       "\n",
       "   Euler Number Avg  Extent Avg  Filled Area Avg  \\\n",
       "0          0.961207    0.765292        17.834052   \n",
       "\n",
       "                      Inertia Tensor Eigenvalues Avg  \\\n",
       "0  1.754462970240409, 1.2999550309352839, 0.63659...   \n",
       "\n",
       "   Volume Avg (Physical Space)  Surface Area Avg (Physical Space)  \\\n",
       "0                    17.834052                          37.992821   \n",
       "\n",
       "   Sphericity Avg (Physical Space)  Aspect Ratio Avg (Major/Minor)  \n",
       "0                         0.867058                             inf  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OutputMetadata():\n",
    "    def __init__(self, img):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_stack = img\n",
    "        self.properties()\n",
    "\n",
    "    def properties(self):\n",
    "            squeeze = np.squeeze(self.image_stack)\n",
    "            squeeze = squeeze.astype(int)  #solved -- NB\n",
    "            # print(squeeze.shape)\n",
    "            # print(squeeze.dtype)\n",
    "            labeled, numfeatures = label(squeeze)\n",
    "            properties = ps.metrics.regionprops_3D(labeled)\n",
    "\n",
    "            # Create an empty list to store dictionaries of property values\n",
    "            property_dicts = []\n",
    "\n",
    "            #loop through regions\n",
    "            for pr in properties:\n",
    "                property_dict = {\n",
    "                    'Label': pr.label,\n",
    "                    'Area': pr.area,\n",
    "                    'Centroid': pr.centroid,\n",
    "                    'Equivalent Diameter': pr.equivalent_diameter,\n",
    "                    'Euler Number': pr.euler_number,\n",
    "                    'Extent': pr.extent,\n",
    "                    'Filled Area': pr.filled_area,\n",
    "                    'Inertia Tensor Eigvals': pr.inertia_tensor_eigvals,\n",
    "                    'Volume (Physical Space)': pr.volume,\n",
    "                    'Surface Area (Physical Space)': pr.surface_area,\n",
    "                    'Sphericity (Physical Space)': pr.sphericity,\n",
    "                    'Aspect Ratio (Major/Minor)': np.sqrt(pr.inertia_tensor_eigvals[0] / pr.inertia_tensor_eigvals[-1])\n",
    "                }\n",
    "                property_dicts.append(property_dict)\n",
    "\n",
    "                # print('append')\n",
    "\n",
    "            # Create a pandas DataFrame from the list of property dictionaries\n",
    "            df = pd.DataFrame(property_dicts)\n",
    "            summary_metadata = {}\n",
    "            # Calculate the statistics\n",
    "            total_structures = numfeatures  # Assuming 'df' is your existing DataFrame #rows\n",
    "            area_avg = df[\"Area\"].mean()\n",
    "            centroid_avg = np.mean(df['Centroid'].to_list(), axis=0)\n",
    "            equivalent_diameter_avg = df[\"Equivalent Diameter\"].mean()\n",
    "            euler_avg = df[\"Euler Number\"].mean()\n",
    "            extent_avg = df[\"Extent\"].mean()\n",
    "            filled_area_avg = df[\"Filled Area\"].mean()\n",
    "            inertia_avg = np.mean(df['Inertia Tensor Eigvals'].to_list(), axis=0)\n",
    "            volume_avg = df['Volume (Physical Space)'].mean()\n",
    "            surface_area_avg = df['Surface Area (Physical Space)'].mean()\n",
    "            sphericity_avg = df['Sphericity (Physical Space)'].mean()\n",
    "            aspect_ratio_avg = df['Aspect Ratio (Major/Minor)'].mean()\n",
    "\n",
    "                       \n",
    "            summary_metadata = {\n",
    "                'Timestep': 0,\n",
    "                'Total Structures': total_structures,\n",
    "                'Area Avg': area_avg,\n",
    "                'Centroid Avg': tuple(centroid_avg),\n",
    "                'Equivalent Diameter Avg': equivalent_diameter_avg,\n",
    "                'Euler Number Avg': euler_avg,\n",
    "                'Extent Avg': extent_avg,\n",
    "                'Filled Area Avg': filled_area_avg,\n",
    "                'Inertia Tensor Eigenvalues Avg': tuple(inertia_avg),\n",
    "                'Volume Avg (Physical Space)': volume_avg,\n",
    "                'Surface Area Avg (Physical Space)': surface_area_avg,\n",
    "                'Sphericity Avg (Physical Space)': sphericity_avg,\n",
    "                'Aspect Ratio Avg (Major/Minor)': aspect_ratio_avg\n",
    "            }\n",
    "\n",
    "            def convert_to_string(coloumn):\n",
    "                return coloumn.apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            # Formatting the 'Centroid' and 'Inertia Tensor Eigvals' columns\n",
    "            # Coverts tuple lists to string\n",
    "            df['Centroid'] = df['Centroid'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            df['Inertia Tensor Eigvals'] = df['Inertia Tensor Eigvals'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            # print(df)\n",
    "            print(summary_metadata)\n",
    "            self.summary_metadata_df = pd.DataFrame([summary_metadata])\n",
    "            self.summary_metadata_df['Centroid Avg'] = self.summary_metadata_df['Centroid Avg'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            self.summary_metadata_df['Inertia Tensor Eigenvalues Avg'] = self.summary_metadata_df['Inertia Tensor Eigenvalues Avg'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            # df['Centroid'] = df['Centroid'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            # df['Inertia Tensor Eigvals'] = df['Inertia Tensor Eigvals'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "        \n",
    "\n",
    "my_props = OutputMetadata(binarisedImageStack)\n",
    "\n",
    "df = my_props.summary_metadata_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'downloads\\\\here\\\\test.csv'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "filename_morph = \"test.tiff\"\n",
    "morph_output_path = \"downloads\\here\"\n",
    "base_filename = os.path.splitext(filename_morph)[0]\n",
    "csv_filename = f\"{base_filename}.csv\"\n",
    "new_morph_path = os.path.join(morph_output_path, csv_filename)\n",
    "# df.to_csv(self.new_morph_path, index =False)\n",
    "new_morph_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Timestep': 0, 'Total Structures': 464, 'Area Avg': 17.834051724137932, 'Centroid Avg': (5.073049734062022, 483.2219390034362, 419.8420927874811), 'Equivalent Diameter Avg': 2.4150695340725914, 'Euler Number Avg': 0.9612068965517241, 'Extent Avg': 0.7652916211166431, 'Filled Area Avg': 17.834051724137932, 'Inertia Tensor Eigenvalues Avg': (1.754462970240409, 1.2999550309352839, 0.6365924067206375), 'Volume Avg (Physical Space)': 17.834051724137932, 'Surface Area Avg (Physical Space)': 37.992821316266884, 'Sphericity Avg (Physical Space)': 0.8670581316534879, 'Aspect Ratio Avg (Major/Minor)': inf}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestep</th>\n",
       "      <th>Total Structures</th>\n",
       "      <th>Area Avg</th>\n",
       "      <th>Centroid Avg</th>\n",
       "      <th>Equivalent Diameter Avg</th>\n",
       "      <th>Euler Number Avg</th>\n",
       "      <th>Extent Avg</th>\n",
       "      <th>Filled Area Avg</th>\n",
       "      <th>Inertia Tensor Eigenvalues Avg</th>\n",
       "      <th>Volume Avg (Physical Space)</th>\n",
       "      <th>Surface Area Avg (Physical Space)</th>\n",
       "      <th>Sphericity Avg (Physical Space)</th>\n",
       "      <th>Aspect Ratio Avg (Major/Minor)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>464</td>\n",
       "      <td>17.834052</td>\n",
       "      <td>5.073049734062022, 483.2219390034362, 419.8420...</td>\n",
       "      <td>2.41507</td>\n",
       "      <td>0.961207</td>\n",
       "      <td>0.765292</td>\n",
       "      <td>17.834052</td>\n",
       "      <td>1.754462970240409, 1.2999550309352839, 0.63659...</td>\n",
       "      <td>17.834052</td>\n",
       "      <td>37.992821</td>\n",
       "      <td>0.867058</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestep  Total Structures   Area Avg  \\\n",
       "0         0               464  17.834052   \n",
       "\n",
       "                                        Centroid Avg  Equivalent Diameter Avg  \\\n",
       "0  5.073049734062022, 483.2219390034362, 419.8420...                  2.41507   \n",
       "\n",
       "   Euler Number Avg  Extent Avg  Filled Area Avg  \\\n",
       "0          0.961207    0.765292        17.834052   \n",
       "\n",
       "                      Inertia Tensor Eigenvalues Avg  \\\n",
       "0  1.754462970240409, 1.2999550309352839, 0.63659...   \n",
       "\n",
       "   Volume Avg (Physical Space)  Surface Area Avg (Physical Space)  \\\n",
       "0                    17.834052                          37.992821   \n",
       "\n",
       "   Sphericity Avg (Physical Space)  Aspect Ratio Avg (Major/Minor)  \n",
       "0                         0.867058                             inf  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class OutputMetadata():\n",
    "    def __init__(self, img):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_stack = img\n",
    "        self.properties_summary()\n",
    "\n",
    "    def properties_summary(self):\n",
    "            squeeze = np.squeeze(self.image_stack)\n",
    "            squeeze = squeeze.astype(int)  #solved -- NB\n",
    "            # print(squeeze.shape)\n",
    "            # print(squeeze.dtype)\n",
    "            labeled, numfeatures = label(squeeze)\n",
    "            properties = ps.metrics.regionprops_3D(labeled)\n",
    "\n",
    "            # Create an empty list to store dictionaries of property values\n",
    "            property_dicts = []\n",
    "\n",
    "            #loop through regions\n",
    "            for pr in properties:\n",
    "                property_dict = {\n",
    "                    'Label': pr.label,\n",
    "                    'Area': pr.area,\n",
    "                    'Centroid': pr.centroid,\n",
    "                    'Equivalent Diameter': pr.equivalent_diameter,\n",
    "                    'Euler Number': pr.euler_number,\n",
    "                    'Extent': pr.extent,\n",
    "                    'Filled Area': pr.filled_area,\n",
    "                    'Inertia Tensor Eigvals': pr.inertia_tensor_eigvals,\n",
    "                    'Volume (Physical Space)': pr.volume,\n",
    "                    'Surface Area (Physical Space)': pr.surface_area,\n",
    "                    'Sphericity (Physical Space)': pr.sphericity,\n",
    "                    'Aspect Ratio (Major/Minor)': np.sqrt(pr.inertia_tensor_eigvals[0] / pr.inertia_tensor_eigvals[-1])\n",
    "                }\n",
    "                property_dicts.append(property_dict)\n",
    "\n",
    "            # Create a pandas DataFrame from the list of property dictionaries\n",
    "            df = pd.DataFrame(property_dicts)\n",
    "            \n",
    "            # Calculate the statistics\n",
    "            total_structures = numfeatures  # Assuming 'df' is your existing DataFrame #rows\n",
    "            area_avg = df[\"Area\"].mean()\n",
    "            centroid_avg = np.mean(df['Centroid'].to_list(), axis=0)\n",
    "            equivalent_diameter_avg = df[\"Equivalent Diameter\"].mean()\n",
    "            euler_avg = df[\"Euler Number\"].mean()\n",
    "            extent_avg = df[\"Extent\"].mean()\n",
    "            filled_area_avg = df[\"Filled Area\"].mean()\n",
    "            inertia_avg = np.mean(df['Inertia Tensor Eigvals'].to_list(), axis=0)\n",
    "            volume_avg = df['Volume (Physical Space)'].mean()\n",
    "            surface_area_avg = df['Surface Area (Physical Space)'].mean()\n",
    "            sphericity_avg = df['Sphericity (Physical Space)'].mean()\n",
    "            aspect_ratio_avg = df['Aspect Ratio (Major/Minor)'].mean()\n",
    "            \n",
    "\n",
    "            summary_metadata = []\n",
    "            summary_metadata_dict = {\n",
    "                'Timestep': 0, # self.stack_dict[\"time_step\"]\n",
    "                'Total Structures': total_structures,\n",
    "                'Area Avg': area_avg,\n",
    "                'Centroid Avg': tuple(centroid_avg),\n",
    "                'Equivalent Diameter Avg': equivalent_diameter_avg,\n",
    "                'Euler Number Avg': euler_avg,\n",
    "                'Extent Avg': extent_avg,\n",
    "                'Filled Area Avg': filled_area_avg,\n",
    "                'Inertia Tensor Eigenvalues Avg': tuple(inertia_avg),\n",
    "                'Volume Avg (Physical Space)': volume_avg,\n",
    "                'Surface Area Avg (Physical Space)': surface_area_avg,\n",
    "                'Sphericity Avg (Physical Space)': sphericity_avg,\n",
    "                'Aspect Ratio Avg (Major/Minor)': aspect_ratio_avg\n",
    "            }\n",
    "            summary_metadata.append(summary_metadata_dict)\n",
    "            \n",
    "            \n",
    "            print(summary_metadata)\n",
    "            self.summary_metadata_df = pd.DataFrame(summary_metadata)\n",
    "            self.summary_metadata_df['Centroid Avg'] = self.summary_metadata_df['Centroid Avg'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            self.summary_metadata_df['Inertia Tensor Eigenvalues Avg'] = self.summary_metadata_df['Inertia Tensor Eigenvalues Avg'].apply(lambda x: f\"{x[0]}, {x[1]}, {x[2]}\")\n",
    "            \n",
    "            # path = r\"c:\\Users\\dell\\Downloads\"\n",
    "            # summary_path = path + \"/time_series_summary.csv\"\n",
    "       \n",
    "            # summary_csv = self.summary_metadata_df.to_csv(summary_path, index =False)\n",
    "            path_x = r\"c:\\Users\\dell\\Downloads\\summary.xlsx\"\n",
    "            summary_csv = self.summary_metadata_df.to_excel(path_x, index =False)\n",
    "\n",
    "my_props = OutputMetadata(binarisedImageStack)\n",
    "my_props.summary_metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, label\n",
    "# img = read_img[0, :, :, :, :]\n",
    "# print(img.shape)\n",
    "img_gray = cv2.cvtColor(slicexyx, cv2.COLOR_BGR2GRAY)\n",
    "        #print(f\"SHAPE OF PROC {img.shape}\")    \n",
    "_, result = cv2.threshold(\n",
    "    src=img_gray,\n",
    "    thresh=100,\n",
    "    maxval=255,\n",
    "    type=cv2.THRESH_BINARY,\n",
    ")\n",
    "img_rehsape = result[:, :, np.newaxis]\n",
    "\n",
    "# Assuming self.image_stack contains the binarized image stack\n",
    "squeeze = np.squeeze(img_rehsape)\n",
    "squeeze = squeeze.astype(int)  # Convert to int if not already\n",
    "\n",
    "# # Smooth the image using Gaussian filter (optional)\n",
    "# smoothed_image = gaussian_filter(squeeze, sigma=1)\n",
    "\n",
    "## Lable node ------------------------------------\n",
    "# Label connected components\n",
    "labeled, num_features = label(squeeze)\n",
    "\n",
    "# Calculate region areas\n",
    "region_areas = np.bincount(labeled.ravel())[1:]\n",
    "\n",
    "\n",
    "# Create a mask to filter regions below the volume threshold\n",
    "mask = np.zeros_like(labeled, dtype=bool)\n",
    "mask[np.isin(labeled, np.nonzero(region_areas >= 5)[0] + 1)] = True\n",
    "\n",
    "# Apply the mask to the original image\n",
    "filtered_image = squeeze * mask.astype(squeeze.dtype)\n",
    "\n",
    "# Count the number of structures\n",
    "num_structures = np.count_nonzero(mask)\n",
    "\n",
    "# Print the number of structures\n",
    "print(\"Number of structures:\", num_structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_tiff_dim(f_path):\n",
    "        tif_file = tiff.TiffFile(f_path)\n",
    "        # Check for TIFF metadata tags\n",
    "        metadata = tif_file.pages[0].tags\n",
    "        if metadata:\n",
    "            # print(\"Metadata Tags:\")\n",
    "            for tag_name, tag in metadata.items():\n",
    "                print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "            #set dimension to 0 when a new tiff file is processed\n",
    "            dimension = [1,1,1,1,1] #dim, slices , time\n",
    "            \n",
    "            \n",
    "            #  T Z Y X C  (F, Z, H, W, C)\n",
    "            #  0 1 2 3 4\n",
    "            \n",
    "            if 256 in metadata: #width\n",
    "                            # Access the tag value directly\n",
    "                            dimension[3] = metadata[256].value\n",
    "            if 257 in metadata: #H\n",
    "                            # Access the tag value directly\n",
    "                            dimension[2] = metadata[257].value\n",
    "            if 277 in metadata: #channels\n",
    "                            # Access the tag value directly\n",
    "                            dimension[4] = metadata[277].value\n",
    "            if 259 in metadata:  # Tag for slices\n",
    "                            print(\"meta\",metadata[259].value)\n",
    "                            dimension[1] = metadata[259].value\n",
    "                        \n",
    "            if 'ImageDescription' in metadata:\n",
    "                    # Access 'ImageDescription' tag\n",
    "                    image_description = metadata['ImageDescription']\n",
    "            \n",
    "                    # Split the 'ImageDescription' string into lines\n",
    "                    description_lines = image_description.value.split('\\n')\n",
    "                    # Parse the lines to extract slices and frames information\n",
    "                    for line in description_lines:\n",
    "                        # if 262 in metadata:  # Tag for frames\n",
    "                        #     dimension[4] = metadata[262].value\n",
    "                        #     print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"slices=\"):\n",
    "                            dimension[1] = int(line.split('=')[1]) #slice\n",
    "                        if line.startswith(\"frames=\"):\n",
    "                            dimension[0] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"frames\", int(line.split('=')[1]))\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"channels=\"):\n",
    "                            dimension[4] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        \n",
    "        else:\n",
    "                print(\"ImageDescription tag not found in metadata.\")\n",
    "                        \n",
    "       \n",
    "        set_widg = [1,1]\n",
    "        set_widg[0] = dimension[0] #t\n",
    "        set_widg[1] = dimension[1] #z\n",
    "      \n",
    "        return dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input image\n",
    "image_filepath = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\venvs\\sk_env2\\Lib\\site-packages\\ryven\\skripsie_projects\\Control_2.tif\"\n",
    "image_data = tiff.imread(image_filepath)\n",
    "image_data = ((image_data / np.max(image_data)) * 255).astype(np.uint8)\n",
    "print(image_data.shape)\n",
    "print(len(image_data[2]))\n",
    "\n",
    "#find dimentions \n",
    "dim = id_tiff_dim(image_filepath)\n",
    "print(dim)\n",
    "\n",
    "if image_data.shape[-3] <= 4:\n",
    "                    \n",
    "                    # dim = [1, 15, 1024, 1024, 3]\n",
    "                    print(\"Strange dimension\")\n",
    "                    #if no time step data \n",
    "                    if len(image_data.shape) == 4: \n",
    "                        print(f'length {len(image_data.shape)}')\n",
    "                        image_data = image_data[np.newaxis,:,:,:,:]\n",
    "\n",
    "                    # Create an empty array with the specified dimensions\n",
    "                    image_data_stacked = np.empty(dim, dtype=np.uint8)\n",
    "\n",
    "                    num_time_frames = dim[0]  # Get the number of time frames\n",
    "                    \n",
    "                    for t in range(num_time_frames):  # Iterate over the time frames\n",
    "                        for i in range(dim[1]):  # Iterate over the images in each time frame\n",
    "                            # Get the red, green, and blue channels for the i-th image in the t-th time frame\n",
    "                            print(i)\n",
    "                            chan_0 = image_data[t, i, 0, :, :]  # Assuming the first dimension is time frame, then image index\n",
    "                            chan_1 = image_data[t, i, 1, :, :]\n",
    "                            chan_2 = image_data[t, i, 2, :, :]\n",
    "                            \n",
    "                            # Stack the channels along the last axis\n",
    "                            image_data_stacked[t, i, :, :, 0] = chan_0\n",
    "                            image_data_stacked[t, i, :, :, 1] = chan_1\n",
    "                            image_data_stacked[t, i, :, :, 2] = chan_2   \n",
    "                            # if have a an alpha channel\n",
    "                            if image_data.shape[2] >= 4:\n",
    "                                chan_3 = image_data[t, i, 3, :, :] \n",
    "                                image_data_stacked[t, i, :, :, 3] = chan_3 \n",
    "\n",
    "                            # if have a an alpha channel\n",
    "                            if image_data.shape[2] == 5:\n",
    "                                chan_4 = image_data[t, i, 4, :, :] \n",
    "                                image_data_stacked[t, i, :, :, 4] = chan_4 \n",
    "\n",
    "                    print(image_data_stacked.shape)   \n",
    "\n",
    "                    image_data = image_data_stacked \n",
    "                # ---------------------------------------------------------------------------------           \n",
    "                    \n",
    "reshaped_data = image_data.reshape(dim)\n",
    "print(\"reshaped\", reshaped_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\venvs\\sk_env2\\Lib\\site-packages\\ryven\\skripsie_projects\\Control_2.tif\"\n",
    "# tif_file = tiff.TiffFile(path)\n",
    "# image = tiff.imread(path)\n",
    "\n",
    "# # metadata = tif_file.pages[0].tags\n",
    "# # if metadata:\n",
    "# #      # print(\"Metadata Tags:\")\n",
    "# #     for tag_name, tag in metadata.items():\n",
    "# #         print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "# print(image.shape)\n",
    "# print(np.max(image[9,0,:,:]))\n",
    "# print(np.max(image[9,1,:,:]))\n",
    "# print(np.max(image[9,2,:,:]))\n",
    "# # Slice\n",
    "# img = image[:, :, :, :]\n",
    "# # Normlize for 8bit PyQt widget\n",
    "# img_norm = ((img / np.max(img)) * 255).astype(np.uint8)\n",
    "# print(\"Img norm\", img_norm.shape)\n",
    "img = reshaped_data[0, :, :, :, :]\n",
    "print(img.shape)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        #print(f\"SHAPE OF PROC {img.shape}\")    \n",
    "_, result = cv2.threshold(\n",
    "    src=img_gray,\n",
    "    thresh=100,\n",
    "    maxval=255,\n",
    "    type=cv2.THRESH_BINARY,\n",
    ")\n",
    "img_rehsape = result[:, :, np.newaxis]\n",
    "\n",
    "# Assuming self.image_stack contains the binarized image stack\n",
    "squeeze = np.squeeze(img_rehsape)\n",
    "squeeze = squeeze.astype(int)  # Convert to int if not already\n",
    "\n",
    "# Smooth the image using Gaussian filter (optional)\n",
    "smoothed_image = gaussian_filter(squeeze, sigma=1)\n",
    "\n",
    "# Label connected components\n",
    "labeled, num_features = label(smoothed_image)\n",
    "\n",
    "# Selected value for structure size\n",
    "selected_value = 100  # Number of pixels\n",
    "\n",
    "# Initialize the count of structures\n",
    "num_structures = 0\n",
    "\n",
    "# Loop through each labeled region\n",
    "for label_id in range(1, num_features+1):\n",
    "    # Calculate the area (number of pixels) of the current labeled region\n",
    "    region_area = np.sum(labeled == label_id)\n",
    "    \n",
    "    # Check if the region's area is greater than the selected value\n",
    "    if region_area >= selected_value:\n",
    "        # Increment the count of structures\n",
    "        num_structures += 1\n",
    "\n",
    "print(\"Number of structures:\", num_structures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to CSV with different sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'Name': ['John', 'Alice', 'Bob'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "data2 = {\n",
    "    'Name': ['Emma', 'Olivia', 'Dave'],\n",
    "    'Age': [1, 2, 3],\n",
    "    'City': ['Stb', 'Los Angeles', 'CT']\n",
    "}\n",
    "\n",
    "df1 = pd.DataFrame(data)\n",
    "df2 = pd.DataFrame(data2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"C:\\Users\\dell\\Downloads\"\n",
    "csv_file1 = output_path + r\"\\csvd1.csv\"\n",
    "df1.to_csv(csv_file1, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = r'C:\\Users\\dell\\Downloads\\csvd1.csv'\n",
    "\n",
    "# Start Excel application\n",
    "excel = win32com.client.Dispatch(\"Excel.Application\")\n",
    "excel.Visible = False  # Make Excel visible (optional)\n",
    "\n",
    "# Open the CSV file in Excel\n",
    "workbook = excel.Workbooks.OpenText(\n",
    "    csv_file_path,\n",
    "    DataType=1,  # Delimited\n",
    "    TextQualifier=1,  # Double quote\n",
    "    ConsecutiveDelimiter=True,\n",
    "    Tab=False,  # Not using tab delimiter\n",
    "    Semicolon=False,  # Not using semicolon delimiter\n",
    "    Comma=True  # Comma delimiter\n",
    ")\n",
    "\n",
    "# Save the workbook (optional)\n",
    "workbook.SaveAs(r'C:\\Users\\dell\\Downloads\\excel_file.xlsx')\n",
    "\n",
    "# Close the workbook and Excel application\n",
    "workbook.Close()\n",
    "excel.Quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import win32com.client\n",
    "\n",
    "# Path to the CSV file\n",
    "csv_file_path = r'C:\\Users\\dell\\Downloads\\csvd1.csv'\n",
    "# Start Excel application\n",
    "excel = win32com.client.Dispatch(\"Excel.Application\")\n",
    "excel.Visible = True  # Make Excel visible (optional)\n",
    "\n",
    "# Open the CSV file in Excel\n",
    "workbook = excel.Workbooks.Open(csv_file_path)\n",
    "\n",
    "# Save the workbook as an Excel file\n",
    "excel_file_path = r'C:\\Users\\dell\\Downloads\\excel_file.xlsx'\n",
    "workbook.SaveAs(excel_file_path, FileFormat=51)  # FileFormat=51 for .xlsx format\n",
    "\n",
    "# Close the workbook and Excel application\n",
    "workbook.Close()\n",
    "excel.Quit()\n",
    "\n",
    "print(f\"CSV file '{csv_file_path}' successfully saved as Excel file '{excel_file_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Sample DataFrames\n",
    "data = {\n",
    "    'Sheet1': pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}),\n",
    "    'Sheet2': pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12]})\n",
    "}\n",
    "\n",
    "# Write each DataFrame to a separate CSV file\n",
    "for sheet_name, df in data.items():\n",
    "    # Define the file path for each CSV file\n",
    "    csv_file = f'{sheet_name}.csv'\n",
    "    # Write the DataFrame to the CSV file\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(\"CSV files created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(row_m,col_m, row, col):\n",
    "    max = row_m+col_m\n",
    "    print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check(1,10,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.stack_dict = {\n",
    "#             \"time_step\": self.frame,\n",
    "#             \"colour\": {\n",
    "#                 \"red\": 100, #If that channel does not exsit set it to 100 \n",
    "#                 \"green\": 100,\n",
    "#                 \"blue\": 100,\n",
    "#                 \"magenta\": 100,\n",
    "#                 \"cyan\": 100\n",
    "#             }\n",
    "#         }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image colour prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import image and prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_tiff_dim(f_path):\n",
    "        tif_file = tiff.TiffFile(f_path)\n",
    "        # Check for TIFF metadata tags\n",
    "        metadata = tif_file.pages[0].tags\n",
    "        if metadata:\n",
    "            # print(\"Metadata Tags:\")\n",
    "            for tag_name, tag in metadata.items():\n",
    "                print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "            #set dimension to 0 when a new tiff file is processed\n",
    "            dimension = [1,1,1,1,1] #dim, slices , time\n",
    "            \n",
    "            \n",
    "            #  T Z Y X C  (F, Z, H, W, C)\n",
    "            #  0 1 2 3 4\n",
    "            \n",
    "            if 256 in metadata: #width\n",
    "                            # Access the tag value directly\n",
    "                            dimension[3] = metadata[256].value\n",
    "            if 257 in metadata: #H\n",
    "                            # Access the tag value directly\n",
    "                            dimension[2] = metadata[257].value\n",
    "            if 277 in metadata: #channels\n",
    "                            # Access the tag value directly\n",
    "                            dimension[4] = metadata[277].value\n",
    "            if 259 in metadata:  # Tag for slices\n",
    "                            print(\"meta\",metadata[259].value)\n",
    "                            dimension[1] = metadata[259].value\n",
    "                        \n",
    "            if 'ImageDescription' in metadata:\n",
    "                    # Access 'ImageDescription' tag\n",
    "                    image_description = metadata['ImageDescription']\n",
    "            \n",
    "                    # Split the 'ImageDescription' string into lines\n",
    "                    description_lines = image_description.value.split('\\n')\n",
    "                    # Parse the lines to extract slices and frames information\n",
    "                    for line in description_lines:\n",
    "                        # if 262 in metadata:  # Tag for frames\n",
    "                        #     dimension[4] = metadata[262].value\n",
    "                        #     print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"slices=\"):\n",
    "                            dimension[1] = int(line.split('=')[1]) #slice\n",
    "                        if line.startswith(\"frames=\"):\n",
    "                            dimension[0] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"frames\", int(line.split('=')[1]))\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"channels=\"):\n",
    "                            dimension[4] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        \n",
    "        else:\n",
    "                print(\"ImageDescription tag not found in metadata.\")\n",
    "                        \n",
    "       \n",
    "        set_widg = [1,1]\n",
    "        set_widg[0] = dimension[0] #t\n",
    "        set_widg[1] = dimension[1] #z\n",
    "      \n",
    "        return dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input image\n",
    "image_filepath = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\venvs\\sk_env2\\Lib\\site-packages\\ryven\\skripsie_projects\\Control_2.tif\"\n",
    "image_data = tiff.imread(image_filepath)\n",
    "image_data = ((image_data / np.max(image_data)) * 255).astype(np.uint8)\n",
    "print(image_data.shape)\n",
    "print(len(image_data[2]))\n",
    "\n",
    "#find dimentions \n",
    "dim = id_tiff_dim(image_filepath)\n",
    "print(dim)\n",
    "\n",
    "#select slice\n",
    "img = image_data[9,:,:,:]\n",
    "\n",
    "# IF shape: ZCXY ---------------------------------------------------------------\n",
    "# Change to TZXYC\n",
    "if image_data.shape[-3] <= 4:\n",
    "    \n",
    "    # dim = [1, 15, 1024, 1024, 3]\n",
    "    print(\"Strange dimension\")\n",
    "    #if no time step data \n",
    "    if len(image_data.shape) == 4: \n",
    "        print(f'length {len(image_data.shape)}')\n",
    "        image_data = image_data[np.newaxis,:,:,:,:]\n",
    "\n",
    "    # Create an empty array with the specified dimensions\n",
    "    image_data_stacked = np.empty(dim, dtype=np.uint8)\n",
    "\n",
    "    num_time_frames = dim[0]  # Get the number of time frames\n",
    "    \n",
    "    for t in range(num_time_frames):  # Iterate over the time frames\n",
    "        for i in range(dim[1]):  # Iterate over the images in each time frame\n",
    "            # Get the red, green, and blue channels for the i-th image in the t-th time frame\n",
    "            print(i)\n",
    "            chan_0 = image_data[t, i, 0, :, :]  # Assuming the first dimension is time frame, then image index\n",
    "            chan_1 = image_data[t, i, 1, :, :]\n",
    "            chan_2 = image_data[t, i, 2, :, :]\n",
    "            \n",
    "            # Stack the channels along the last axis\n",
    "            image_data_stacked[t, i, :, :, 0] = chan_0\n",
    "            image_data_stacked[t, i, :, :, 1] = chan_1\n",
    "            image_data_stacked[t, i, :, :, 2] = chan_2   \n",
    "            # if have a an alpha channel\n",
    "            if image_data.shape[2] >= 4:\n",
    "                chan_3 = image_data[t, i, 3, :, :] \n",
    "                image_data_stacked[t, i, :, :, 3] = chan_3 \n",
    "\n",
    "            # if have a an alpha channel\n",
    "            if image_data.shape[2] == 5:\n",
    "                chan_4 = image_data[t, i, 4, :, :] \n",
    "                image_data_stacked[t, i, :, :, 4] = chan_4 \n",
    "\n",
    "print(image_data_stacked.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select image slice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_data_stacked[0,9,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Widget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100, #If that channel does not exsit set it to 100 \n",
    "                \"green\": 1,\n",
    "                \"blue\": 2,\n",
    "                \"magenta\": 0,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "\n",
    "        # Extract individual channels\n",
    "        magenta_channel = img[:,:,0]\n",
    "        green_channel = img[:,:,1]\n",
    "        blue_channel = img[:,:,2]\n",
    "        red_channel = np.zeros_like(blue_channel)\n",
    "\n",
    "        # Add magenta channel to red and blue channels\n",
    "        red_channel = np.add(red_channel, magenta_channel)\n",
    "        blue_channel = np.add(blue_channel, magenta_channel)\n",
    "\n",
    "        # Clip values to ensure they remain within the valid range [0, 255]\n",
    "        red_channel = np.clip(red_channel, 0, 255)\n",
    "        blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "        # Combine channels back into image data\n",
    "        img = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "        # try:\n",
    "        if img.shape[-1] == 1:\n",
    "            # Grayscale image\n",
    "            qt_image = QImage(img.data, img.shape[1], img.shape[0], img.shape[1], QImage.Format_Grayscale8)\n",
    "            # #print(\"came here for Sliderwidget\")\n",
    "        elif img.shape[-1] == 3:\n",
    "            h, w, ch = img.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888) #Format_RGB888\n",
    "        elif img.shape[-1] == 4:\n",
    "            h, w, ch = img.shape\n",
    "            #print(f\"ch: {ch}\")\n",
    "            bytes_per_line = ch * 4\n",
    "            qt_image = QImage(img.data, w, h, QImage.Format_RGBA8888) #Format_RGB888\n",
    "        if qt_image is not None:\n",
    "            # Calculate the target size for scaling\n",
    "            scale_factor = 0.7  # Increase the scaling factor for clarity\n",
    "            if qt_image.width() < 400:\n",
    "                scale_factor = 1\n",
    "            if qt_image.width() > 900:\n",
    "                scale_factor = 0.5\n",
    "            target_width = int(qt_image.width() * scale_factor)\n",
    "            # Use scaledToWidth to reduce the size while maintaining aspect ratio\n",
    "            scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "            \n",
    "            # Set the scaled pixmap\n",
    "            self.image_label.setPixmap(scaled_pixmap)\n",
    "          \n",
    "\n",
    "# Create an instance of the QApplication object\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = Widget()\n",
    "\n",
    "# Show the image in the widget\n",
    "widget.show_image(img)\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_label = QLabel()\n",
    "layout1 = QVBoxLayout()\n",
    "layout1.addWidget(image_label)  \n",
    "\n",
    "if img.shape[-1] == 1:\n",
    "    # Grayscale image\n",
    "    qt_image = QImage(img.data, img.shape[1], img.shape[0], img.shape[1], QImage.Format_Grayscale8)\n",
    "    # #print(\"came here for Sliderwidget\")\n",
    "elif img.shape[-1] == 3:\n",
    "    h, w, ch = img.shape\n",
    "    bytes_per_line = ch * w\n",
    "    qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888) #Format_RGB888\n",
    "elif img.shape[-1] == 4:\n",
    "    h, w, ch = img.shape\n",
    "    #print(f\"ch: {ch}\")\n",
    "    bytes_per_line = ch * 4\n",
    "    qt_image = QImage(img.data, w, h, QImage.Format_RGBA8888) #Format_RGB888\n",
    "if qt_image is not None:\n",
    "    # Calculate the target size for scaling\n",
    "    scale_factor = 0.7  # Increase the scaling factor for clarity\n",
    "    if qt_image.width() < 400:\n",
    "        scale_factor = 1\n",
    "    if qt_image.width() > 900:\n",
    "        scale_factor = 0.5\n",
    "    target_width = int(qt_image.width() * scale_factor)\n",
    "    # Use scaledToWidth to reduce the size while maintaining aspect ratio\n",
    "    scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "    \n",
    "    # Set the scaled pixmap\n",
    "    image_label.setPixmap(scaled_pixmap)\n",
    "    \n",
    "    # # Resize the widget to match the pixmap size\n",
    "    # self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "    \n",
    "    # # Ensure that any necessary updates are performed\n",
    "    # self.node.update_shape()\n",
    "\n",
    "# except Exception as e:\n",
    "#         print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the midpoint indices for the slice to be displayed in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = [1,15,512,512,3]\n",
    "zzval = int(dimension[1] /2)\n",
    "stack = int(dimension[0] / 2)\n",
    "print(zzval, stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baf 1 (20.3).tif\n",
      "C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Deconvolved\\Baf\\Baf 1 (20.3).tif\n",
      "Baf 2 (20.3).tif\n",
      "C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Deconvolved\\Baf\\Baf 2 (20.3).tif\n",
      "Baf3 (20.3).tif\n",
      "C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Deconvolved\\Baf\\Baf3 (20.3).tif\n",
      "C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Deconvolved\\Baf\\BatchProcessed\n",
      "C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Deconvolved\\Baf\\BatchProcessed\\batched_processed_Baf3 (20.3).tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\dell\\\\OneDrive\\\\Documents\\\\Em\\\\2023\\\\Skripsie\\\\Development\\\\Data\\\\Deconvolved\\\\Baf\\\\BatchProcessed\\\\batched_processed_Baf3 (20.3).tif'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r'C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Deconvolved\\Baf'\n",
    "\n",
    "# Loop through files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if os.path.isfile(os.path.join(folder_path, filename)):\n",
    "        print(filename)\n",
    "        file = os.path.join(folder_path, filename)\n",
    "        print(file)\n",
    "        filename = filename\n",
    "\n",
    "new_folder_name = \"BatchProcessed\"  # You can change this to your desired folder name\n",
    "new_folder_path = os.path.join(folder_path, new_folder_name)\n",
    "print(new_folder_path)\n",
    "# os.makedirs(new_folder_path)\n",
    "\n",
    "new_file_path = os.path.join(new_folder_path, \"batched_processed_\" + filename)\n",
    "print(new_file_path)\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = (1,3)\n",
    "tuples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(folder_path)\n",
    "tiff_files = [file for file in files if file.lower().endswith(('.tif', '.tiff'))]\n",
    "num_tiff = len(tiff_files)\n",
    "print(i)\n",
    "if i < num_tiff:\n",
    "        print('perform')\n",
    "        firstfile = tiff_files[i]\n",
    "        print(firstfile)\n",
    "        i+=1\n",
    "# else:\n",
    "#         return\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save RGB images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\fly\\flybrain.tif\"\n",
    "tif_file = tiff.TiffFile(path)\n",
    "img = tiff.imread(path)\n",
    "img_norm = ((img / np.max(img)) * 255).astype(np.uint8)\n",
    "print(img_norm.shape)\n",
    "new_file_path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\fly\\BatchProcessed\\flybrainY.tif\"\n",
    "custom_metadata = {\n",
    "                \"Description\": \"Stack (RGB) preprocessed with Visual Processing Pipeline. Developed using Ryven by Emma Sharratt and Dr Rensue Theart\",\n",
    "                \"Author\": \"Emma Sharratt and Dr Rensue Theart\",\n",
    "                \"Date\": \"Pipeline created in 2023\",\n",
    "                'axes': 'ZCYX' #?????\n",
    "                # \"256\": RGB_stack.shape[2], #W\n",
    "                # \"257\": RGB_stack.shape[1], #H\n",
    "                # \"slices=\": RGB_stack.shape[0],\n",
    "                # \"frames=\": 1,\n",
    "                # \"channels=\": RGB_stack.shape[3],\n",
    "            }\n",
    "tiff.imwrite(new_file_path, img_norm, photometric='rgb', imagej=True, metadata=custom_metadata )\n",
    "# ValueError: ImageJ hyperstack axes must be in TZCYXS order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop down channel options prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QComboBox, QLabel, QVBoxLayout, QWidget\n",
    "\n",
    "class ComboBoxExample(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.old_choice = None\n",
    "        self.new_choice = None\n",
    "\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Combo Box Example')\n",
    "        self.setGeometry(100, 100, 300, 200)\n",
    "\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.combo_box = QComboBox()\n",
    "        self.combo_box.addItems(['Option 1', 'Option 2', 'Option 3'])\n",
    "        self.combo_box.currentIndexChanged.connect(self.onIndexChanged)\n",
    "\n",
    "        self.label_old_choice = QLabel('Old Choice: ')\n",
    "        self.label_new_choice = QLabel('New Choice: ')\n",
    "\n",
    "        layout.addWidget(self.combo_box)\n",
    "        layout.addWidget(self.label_old_choice)\n",
    "        layout.addWidget(self.label_new_choice)\n",
    "\n",
    "        central_widget = QWidget()\n",
    "        central_widget.setLayout(layout)\n",
    "        self.setCentralWidget(central_widget)\n",
    "\n",
    "    def onIndexChanged(self, index):\n",
    "        self.old_choice = self.new_choice\n",
    "        self.new_choice = self.combo_box.currentText()\n",
    "\n",
    "        self.label_old_choice.setText(f'Old Choice: {self.old_choice}')\n",
    "        self.label_new_choice.setText(f'New Choice: {self.new_choice}')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    window = ComboBoxExample()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QComboBox, QLabel, QVBoxLayout, QWidget\n",
    "\n",
    "class combodemo(QWidget):\n",
    "   def __init__(self, parent=None):\n",
    "      super(combodemo, self).__init__(parent)\n",
    "      \n",
    "      layout = QVBoxLayout()\n",
    "      self.cb = QComboBox()\n",
    "      self.cb.addItem(\"C\")\n",
    "      self.cb.addItem(\"C++\")\n",
    "      self.cb.addItems([\"Java\", \"C#\", \"Python\"])\n",
    "      self.cb.currentIndexChanged.connect(self.selectionchange)\n",
    "      \n",
    "      layout.addWidget(self.cb)\n",
    "      self.setLayout(layout)\n",
    "      self.setWindowTitle(\"combo box demo\")\n",
    "\n",
    "   def selectionchange(self, i):\n",
    "      print(\"Items in the list are :\")\n",
    "      \n",
    "      for count in range(self.cb.count()):\n",
    "         print(self.cb.itemText(count))\n",
    "      print(\"Current index\", i, \"selection changed \", self.cb.currentText())\n",
    "\n",
    "def main():\n",
    "   app = QApplication(sys.argv)\n",
    "   ex = combodemo()\n",
    "   ex.show()\n",
    "   sys.exit(app.exec_())\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Updates\n",
    "- Add yellow\n",
    "- Select > None\n",
    "- add image and change colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from qtpy.QtGui import QFont, QImage, QPixmap, QColor\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QComboBox, QLabel, QCheckBox, QPushButton, QSizePolicy, QAbstractItemView \n",
    "from qtpy.QtCore import Qt, Signal, QEvent, QTimer, QObject\n",
    "\n",
    "class ColorChannelWidget(QWidget):\n",
    "    def __init__(self, img2d):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "        self.img2D = img2d\n",
    "\n",
    "    def initUI(self):\n",
    "\n",
    "        # self.old_choice_dict = {\n",
    "        #      \"old_chan_0\": None,\n",
    "        #      \"old_chan_1\": None,\n",
    "        #      \"old_chan_2\": None,\n",
    "        #      \"old_chan_3\": None,\n",
    "        #      \"old_chan_4\": None,\n",
    "        #      \"old_chan_5\": None,\n",
    "        # }   \n",
    "        self.old_choice_array = [None, None, None, None, None, None]\n",
    "        self.color_name = [None, None, None, None, None, None] \n",
    "        # self.old_channel_index = None\n",
    "        self.dropdowns = []\n",
    "        self.checkboxes = []\n",
    "        self.stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"cyan\": 100,\n",
    "                \"yellow\": 100,\n",
    "                \"magenta\": 100                \n",
    "            }\n",
    "        }\n",
    "        self.temp_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"cyan\": 100,\n",
    "                \"yellow\": 100,\n",
    "                \"magenta\": 100                \n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.color_codes = {\n",
    "        'red': 1,\n",
    "        'green': 2,\n",
    "        'blue': 3,\n",
    "        #CHANGED\n",
    "        'cyan': 4,\n",
    "        'yellow': 5,\n",
    "        'magenta': 6\n",
    "        }\n",
    "\n",
    "        self.layout1 = QVBoxLayout()\n",
    "\n",
    "        longest_word_width = max(len(word) for word in self.color_codes.keys())\n",
    "        col1_layout = QVBoxLayout()\n",
    "        col2_layout = QVBoxLayout()\n",
    "\n",
    "        # Add dropdowns to two columns\n",
    "        for i, color in enumerate(self.color_codes.keys()):\n",
    "            label = QLabel(f\"Channel {i}:\")\n",
    "            label.setSizePolicy(QSizePolicy.Fixed, QSizePolicy.Fixed)\n",
    "            label.setMinimumWidth(longest_word_width)\n",
    "            dropdown = QComboBox()\n",
    "            dropdown.addItem(\"Select\")\n",
    "            dropdown.setStyleSheet(\"QComboBox QAbstractItemView { background-color: #091C7F }\")\n",
    "            for color_code in self.color_codes.keys():\n",
    "                dropdown.addItem(color_code)\n",
    "            dropdown.currentIndexChanged.connect(lambda index, i=i, diction=self.temp_dict: self.handle_selection(index, i, diction))\n",
    "            self.dropdowns.append(dropdown)\n",
    "            \n",
    "            row_layout = QHBoxLayout()  # Create a QHBoxLayout for each row\n",
    "            row_layout.addWidget(label)\n",
    "            row_layout.addWidget(dropdown)\n",
    "            \n",
    "            # create two coloumns \n",
    "            if i < len(self.color_codes)/2:\n",
    "                col1_layout.addLayout(row_layout)  # Add the row layout to the column layout\n",
    "            else:\n",
    "                col2_layout.addLayout(row_layout)  # Add the row layout to the column layout\n",
    "\n",
    "        # Add column layouts to the main layout\n",
    "        col_layout = QHBoxLayout()\n",
    "        col_layout.addLayout(col1_layout)\n",
    "        col_layout.addLayout(col2_layout)\n",
    "        self.layout1.addLayout(col_layout)\n",
    "\n",
    "        # warning\n",
    "        self.warning = QLabel('')\n",
    "        self.warning.setStyleSheet('font-size: 1px;')\n",
    "        # self.warning.setStyleSheet('background-color: #BC0000; color: white; font-size: 14px;')\n",
    "        self.layout1.addWidget(self.warning)\n",
    "                \n",
    "        #image\n",
    "        self.image_label = QLabel()\n",
    "\n",
    "        # Create layout for Clear Choices button and Confirm Colour Selection checkbox\n",
    "        self.button_layout = QHBoxLayout()\n",
    "\n",
    "        # Confirm checkbox\n",
    "        self.checkbox = QCheckBox(\"Confirm channel selection \")\n",
    "        self.checkbox.stateChanged.connect(lambda state, diction=self.temp_dict: self.update_dict(state, diction))\n",
    "        self.button_layout.addWidget(self.checkbox)\n",
    "\n",
    "        # Clear button\n",
    "        self.clear_button = QPushButton(\"Clear Choices\")\n",
    "        self.clear_button.clicked.connect(lambda: self.clear_choices(self.stack_dict, self.temp_dict))\n",
    "        self.button_layout.addWidget(self.clear_button)\n",
    "\n",
    "        # Add button layout to the main layout\n",
    "        self.layout1.addLayout(self.button_layout)\n",
    "\n",
    "        # Image\n",
    "        self.layout1.addWidget(self.image_label)   \n",
    "\n",
    "        self.setLayout(self.layout1)\n",
    "        self.setWindowTitle('Color Channel Selector')\n",
    "\n",
    "    def handle_selection(self, index, channel_index, dicttemp):\n",
    "        if index != 0:\n",
    "            # update the specific channel\n",
    "            self.old_choice_array[channel_index] = self.color_name[channel_index]\n",
    "            print(self.old_choice_array)\n",
    "            old_colour = self.old_choice_array[channel_index]\n",
    "            print(old_colour)\n",
    "            if old_colour is not None:\n",
    "                dicttemp[\"colour\"][old_colour] = 100\n",
    "            \n",
    "            \n",
    "            # update dictionary \n",
    "            self.color_name[channel_index] = self.dropdowns[channel_index].currentText()\n",
    "            print(f'old colour_name: {self.old_choice_array}')\n",
    "            # Check if colour already selected\n",
    "            self.warning.setText(' ')\n",
    "            self.warning.setStyleSheet('font-size: 1px;')\n",
    "            for colour in self.old_choice_array:\n",
    "                if colour is not None:\n",
    "                    if self.color_name[channel_index] == colour:\n",
    "                        self.warning.setText(\"WARNING! Please ensure no colours are duplicated\")\n",
    "                        style = \"\"\"\n",
    "                            background-color: #BC0000;\n",
    "                            border-style: outset;\n",
    "                            border-width: 2px;\n",
    "                            border-radius: 10px;\n",
    "                            border-color: beige;\n",
    "                            font: 14px;\n",
    "                            min-width: 10em;\n",
    "                            padding: 6px;\n",
    "                        \"\"\"\n",
    "                        self.warning.setStyleSheet(style)\n",
    "\n",
    "            dicttemp[\"colour\"][self.color_name[channel_index]] = channel_index\n",
    "            print(f\"{self.color_name[channel_index]}: Channel {channel_index}\")\n",
    "            print(self.stack_dict)\n",
    "            # Uncheck the checkbox when a dropdown is changed\n",
    "            if self.checkbox.isChecked():\n",
    "                self.checkbox.setChecked(False)\n",
    "                self.clear_img()\n",
    "\n",
    "    def update_dict(self, state, dicttemp):\n",
    "        if state == 2:  # Checkbox checked state\n",
    "            # add code to check if same colours are chosen?\n",
    "            for color in dicttemp[\"colour\"]:\n",
    "                self.stack_dict[\"colour\"][color] = dicttemp[\"colour\"][color]\n",
    "                # dicttemp[\"colour\"][color] = 100\n",
    "            print(f'update stack: {dicttemp}')\n",
    "            # print(self.stack_dict)   \n",
    "            self.show_image(self.img2D)             \n",
    "                # WILL NEED TO SEND TO SPECIAL NODES LAYER\n",
    "\n",
    "    # def handle_selection(self, index, channel_index, dicttemp):\n",
    "    #     if index != 0:\n",
    "    #         color_name = self.dropdowns[channel_index].currentText()\n",
    "    #         dicttemp[\"colour\"][color_name] = channel_index\n",
    "    #         # Uncheck the checkbox when a dropdown is changed\n",
    "    #         if self.checkbox.isChecked():\n",
    "    #             self.checkbox.setChecked(False)\n",
    "    #             self.clear_img()\n",
    "    #         # self.checkbox.setChecked(False)\n",
    "\n",
    "    # def update_dict(self, state, dicttemp):\n",
    "    #     if state == 2:  # Checkbox checked state\n",
    "    #         # add code to check if same colours are chosen?\n",
    "    #         for color in dicttemp[\"colour\"]:\n",
    "    #             self.stack_dict[\"colour\"][color] = dicttemp[\"colour\"][color]\n",
    "    #             # dicttemp[\"colour\"][color] = 100\n",
    "    #         print(self.stack_dict)   \n",
    "    #         self.show_image(self.img2D)             \n",
    "    #             # WILL NEED TO SEND TO SPECIAL NODES LAYER\n",
    "\n",
    "    def clear_choices(self, dict, dicttemp):\n",
    "        self.checkbox.setChecked(False)\n",
    "        for dropdown in self.dropdowns:\n",
    "            dropdown.setCurrentIndex(0)  # Reset dropdown menu to \"None\"\n",
    "\n",
    "        for color in dict[\"colour\"]:\n",
    "            dict[\"colour\"][color] = 100  # Reset color values to 100\n",
    "            dicttemp[\"colour\"][color] = 100\n",
    "                   \n",
    "        self.old_choice_array = [None, None, None, None, None, None]\n",
    "        self.color_name = [None, None, None, None, None, None] \n",
    "        \n",
    "        self.clear_img()\n",
    "    \n",
    "    def assign_channels_RGB(self, img):\n",
    "        single_chan = img[:, :, 0]\n",
    "        # Initialize RGB channels with zeros\n",
    "        red_channel = np.zeros_like(single_chan)\n",
    "        green_channel = np.zeros_like(single_chan)\n",
    "        blue_channel = np.zeros_like(single_chan)\n",
    "\n",
    "        for color, channel_value in self.stack_dict[\"colour\"].items():\n",
    "            # Check if the channel is part of the image\n",
    "            if channel_value != 100:\n",
    "                # Assign channels based on the color\n",
    "                if color == \"red\":\n",
    "                    red_channel += img[:, :, channel_value]\n",
    "                elif color == \"green\":\n",
    "                    green_channel += img[:, :, channel_value]\n",
    "                elif color == \"blue\":\n",
    "                    blue_channel += img[:, :, channel_value]\n",
    "                elif color == \"cyan\":\n",
    "                    cyan_channel = img[:, :, channel_value]\n",
    "                    green_channel += cyan_channel\n",
    "                    blue_channel += cyan_channel\n",
    "                elif color == \"magenta\":\n",
    "                    magenta_channel = img[:, :, channel_value]\n",
    "                    red_channel += magenta_channel\n",
    "                    blue_channel += magenta_channel\n",
    "                elif color == \"yellow\":\n",
    "                    yellow_channel = img[:, :, channel_value]\n",
    "                    red_channel += yellow_channel\n",
    "                    green_channel += yellow_channel\n",
    "\n",
    "        # Clip values to ensure they remain within the valid range [0, 255]\n",
    "        red_channel = np.clip(red_channel, 0, 255)\n",
    "        green_channel = np.clip(green_channel, 0, 255)\n",
    "        blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "        # Combine channels back into image data\n",
    "        rgb_image_stack = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "\n",
    "        return rgb_image_stack\n",
    "\n",
    "    \n",
    "    def show_image(self, old_img):\n",
    "        # self.resize(800,800)\n",
    "        img = self.assign_channels_RGB(old_img)\n",
    "        \n",
    "        try:\n",
    "            if img.shape[-1] == 1:\n",
    "                # Grayscale image\n",
    "                qt_image = QImage(img.data, img.shape[1], img.shape[0], img.shape[1], QImage.Format_Grayscale8)\n",
    "                # #print(\"came here for Sliderwidget\")\n",
    "            elif img.shape[-1] == 3:\n",
    "                h, w, ch = img.shape\n",
    "                bytes_per_line = ch * w\n",
    "                qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888) #Format_RGB888\n",
    "            elif img.shape[-1] == 4:\n",
    "                h, w, ch = img.shape\n",
    "                #print(f\"ch: {ch}\")\n",
    "                bytes_per_line = ch * 4\n",
    "                qt_image = QImage(img.data, w, h, QImage.Format_RGBA8888) #Format_RGB888\n",
    "            if qt_image is not None:\n",
    "                # Calculate the target size for scaling\n",
    "                scale_factor = 0.7  # Increase the scaling factor for clarity\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                # Use scaledToWidth to reduce the size while maintaining aspect ratio\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                # Set the scaled pixmap\n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                \n",
    "                # Resize the widget to match the pixmap size\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "    \n",
    "    def clear_img(self):\n",
    "         # Create a black image of size 1x1\n",
    "        clr_img = QImage(1, 1, QImage.Format_RGB888)\n",
    "        clr_img.setPixelColor(0, 0, QColor(Qt.black))\n",
    "\n",
    "        self.image_label.setPixmap(QPixmap(clr_img))\n",
    "        #print(self.width(), self.height())\n",
    "        # self.resize(200,50)\n",
    "        # self.node.update_shape() #works the best. But doesnt minimize shape immediately\n",
    "    \n",
    "\n",
    "class ReadImage():\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        #Import image\n",
    "        \n",
    "        self.image_data = tiff.imread(path)\n",
    "\n",
    "        # Normalize - generate dimension list (T,Z,H,W,C)\n",
    "        self.dim = self.id_tiff_dim(path)\n",
    "        # Reshape - STANDARDIZED \n",
    "        self.image_data = ((self.image_data / np.max(self.image_data)) * 255).astype(np.uint8)\n",
    "\n",
    "        # IF shape: ZCXY ---------------------------------------------------------------\n",
    "        # Change to TZXYC\n",
    "        if self.image_data.shape[-3] <= 4:\n",
    "            \n",
    "            # dim = [1, 15, 1024, 1024, 3]\n",
    "            print(\"Strange dimension\")\n",
    "            #if no time step data \n",
    "            if len(self.image_data.shape) == 4: \n",
    "                print(f'length {len(self.image_data.shape)}')\n",
    "                self.image_data = self.image_data[np.newaxis,:,:,:,:]\n",
    "\n",
    "            # Create an empty array with the specified dimensions\n",
    "            image_data_stacked = np.empty(self.dim, dtype=np.uint8)\n",
    "\n",
    "            num_time_frames = self.dim[0]  # Get the number of time frames\n",
    "            \n",
    "            for t in range(num_time_frames):  # Iterate over the time frames\n",
    "                for i in range(self.dim[1]):  # Iterate over the images in each time frame\n",
    "                    # Get the red, green, and blue channels for the i-th image in the t-th time frame\n",
    "                    print(i)\n",
    "                    chan_0 = self.image_data[t, i, 0, :, :]  # Assuming the first dimension is time frame, then image index\n",
    "                    chan_1 = self.image_data[t, i, 1, :, :]\n",
    "                    chan_2 = self.image_data[t, i, 2, :, :]\n",
    "                    \n",
    "                    # Stack the channels along the last axis\n",
    "                    image_data_stacked[t, i, :, :, 0] = chan_0\n",
    "                    image_data_stacked[t, i, :, :, 1] = chan_1\n",
    "                    image_data_stacked[t, i, :, :, 2] = chan_2   \n",
    "                    # if have a an alpha channel\n",
    "                    if self.image_data.shape[2] >= 4:\n",
    "                        chan_3 = self.image_data[t, i, 3, :, :] \n",
    "                        image_data_stacked[t, i, :, :, 3] = chan_3 \n",
    "\n",
    "                    # if have a an alpha channel\n",
    "                    if self.image_data.shape[2] == 5:\n",
    "                        chan_4 = self.image_data[t, i, 4, :, :] \n",
    "                        image_data_stacked[t, i, :, :, 4] = chan_4 \n",
    "\n",
    "            print(image_data_stacked.shape)   \n",
    "\n",
    "            self.image_data = image_data_stacked \n",
    "            self.slice = self.image_data[0,9,:,:,:]\n",
    "            print(f'shape: {self.slice.shape}, type: {type(self.slice)}')\n",
    "        # ---------------------------------------------------------------------------------           \n",
    "        \n",
    "    def id_tiff_dim(self,f_path):\n",
    "        tif_file = tiff.TiffFile(f_path)\n",
    "        # Check for TIFF metadata tags\n",
    "        metadata = tif_file.pages[0].tags\n",
    "        if metadata:\n",
    "            # print(\"Metadata Tags:\")\n",
    "            for tag_name, tag in metadata.items():\n",
    "                print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "            #set dimension to 0 when a new tiff file is processed\n",
    "            dimension = [1,1,1,1,1] #dim, slices , time\n",
    "            \n",
    "            \n",
    "            #  T Z Y X C  (F, Z, H, W, C)\n",
    "            #  0 1 2 3 4\n",
    "            \n",
    "            if 256 in metadata: #width\n",
    "                            # Access the tag value directly\n",
    "                            dimension[3] = metadata[256].value\n",
    "            if 257 in metadata: #H\n",
    "                            # Access the tag value directly\n",
    "                            dimension[2] = metadata[257].value\n",
    "            if 277 in metadata: #channels\n",
    "                            # Access the tag value directly\n",
    "                            dimension[4] = metadata[277].value\n",
    "            if 259 in metadata:  # Tag for slices\n",
    "                            print(\"meta\",metadata[259].value)\n",
    "                            dimension[1] = metadata[259].value\n",
    "                        \n",
    "            if 'ImageDescription' in metadata:\n",
    "                    # Access 'ImageDescription' tag\n",
    "                    image_description = metadata['ImageDescription']\n",
    "            \n",
    "                    # Split the 'ImageDescription' string into lines\n",
    "                    description_lines = image_description.value.split('\\n')\n",
    "                    # Parse the lines to extract slices and frames information\n",
    "                    for line in description_lines:\n",
    "                        # if 262 in metadata:  # Tag for frames\n",
    "                        #     dimension[4] = metadata[262].value\n",
    "                        #     print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"slices=\"):\n",
    "                            dimension[1] = int(line.split('=')[1]) #slice\n",
    "                        if line.startswith(\"frames=\"):\n",
    "                            dimension[0] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"frames\", int(line.split('=')[1]))\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        if line.startswith(\"channels=\"):\n",
    "                            dimension[4] = int(line.split('=')[1]) #frames\n",
    "                            # print(\"dim\",dimension[4])\n",
    "                        \n",
    "        else:\n",
    "                print(\"ImageDescription tag not found in metadata.\")\n",
    "                        \n",
    "        # print(f'Width: {dimension[3]}')\n",
    "        # print(f'Height: {dimension[2]}')\n",
    "        # print(f'Channels: {dimension[4]}')\n",
    "        # print(f\"Slices: {dimension[1]}\")\n",
    "        # print(f\"Frames: {dimension[0]}\")\n",
    "        # print(f'Dimension: {dimension[0]}')\n",
    "        # self.dimension=dimension\n",
    "        set_widg = [1,1]\n",
    "        set_widg[0] = dimension[0] #t\n",
    "        set_widg[1] = dimension[1] #z\n",
    "        # self.SIGNALS.reset_widget.emit(set_widg)\n",
    "        # self.SIGNALS.image_shape.emit(dimension)\n",
    "        # self.stack_dict[\"time_step\"]= 1\n",
    "        # self.zzval= round(set_widg[1]/2)\n",
    "        # if (dimension[0])==1 or (dimension[1])==1:\n",
    "        #     set_widg = [1,1]\n",
    "        #     self.SIGNALS.reset_widget.emit(set_widg)\n",
    "        #     self.stack_dict[\"time_step\"]=0\n",
    "        #     self.zzval=0\n",
    "        print(f'Image dim: {dimension}')\n",
    "        return dimension\n",
    "\n",
    "image_filepath = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Control_2.tif\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    \n",
    "    read_img = ReadImage(image_filepath)\n",
    "    slicedXYC = read_img.slice\n",
    "    widget = ColorChannelWidget(slicedXYC)\n",
    "    #send to function which updates channels which then calls the show image\n",
    "    # widget.show_image(read_img.slice)\n",
    "    # print(read_img.image_data)\n",
    "    widget.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QComboBox, QLabel, QCheckBox, QPushButton, QSizePolicy, QAbstractItemView \n",
    "\n",
    "class ColorChannelWidget(QWidget):\n",
    "    def __init__(self, color_codes):\n",
    "        super().__init__()\n",
    "        self.color_codes = color_codes\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.dropdowns = []\n",
    "        self.checkboxes = []\n",
    "        self.stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "        self.temp_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "\n",
    "        longest_word_width = max(len(word) for word in self.color_codes.keys())\n",
    "        print(longest_word_width)\n",
    "        for i in range(5):\n",
    "            channel_layout = QHBoxLayout()\n",
    "            label = QLabel(f\"Channel {i}:\")\n",
    "            label.setSizePolicy(QSizePolicy.Fixed, QSizePolicy.Fixed)\n",
    "            label.setMinimumWidth(longest_word_width)  # Adjust the multiplier to your preference\n",
    "            dropdown = QComboBox()\n",
    "            dropdown.addItem(\"Select\")\n",
    "            dropdown.setStyleSheet(\"QComboBox QAbstractItemView { background-color: #091C7F }\")\n",
    "            # dropdown.setSizePolicy(QSizePolicy.Fixed, QSizePolicy.Fixed)\n",
    "            # dropdown.setMinimumWidth(longest_word_width) \n",
    "            for color_code in self.color_codes.keys():\n",
    "                dropdown.addItem(color_code)\n",
    "            # dropdown.setStyleSheet(\"QComboBox { background-color: white; }\")  # Set background color\n",
    "            dropdown.currentIndexChanged.connect(lambda index, i=i, diction=self.temp_dict: self.handle_selection(index, i, diction))\n",
    "            channel_layout.addWidget(label)\n",
    "            channel_layout.addWidget(dropdown)\n",
    "            layout.addLayout(channel_layout)\n",
    "            self.dropdowns.append(dropdown)\n",
    "\n",
    "        # Create layout for Clear Choices button and Confirm Colour Selection checkbox\n",
    "        button_layout = QHBoxLayout()\n",
    "\n",
    "        # Confirm checkbox\n",
    "        self.checkbox = QCheckBox(\"Confirm channel selection \")\n",
    "        self.checkbox.stateChanged.connect(lambda state, diction=self.temp_dict: self.update_dict(state, diction))\n",
    "        button_layout.addWidget(self.checkbox)\n",
    "\n",
    "        # Clear button\n",
    "        self.clear_button = QPushButton(\"Clear Choices\")\n",
    "        self.clear_button.clicked.connect(lambda: self.clear_choices(self.stack_dict, self.temp_dict))\n",
    "        button_layout.addWidget(self.clear_button)\n",
    "\n",
    "        # Add button layout to the main layout\n",
    "        layout.addLayout(button_layout)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Color Channel Selector')\n",
    "\n",
    "    def handle_selection(self, index, channel_index, dicttemp):\n",
    "        if index != 0:\n",
    "            color_name = self.dropdowns[channel_index].currentText()\n",
    "            dicttemp[\"colour\"][color_name] = channel_index\n",
    "            # Uncheck the checkbox when a dropdown is changed\n",
    "            self.checkbox.setChecked(False)\n",
    "\n",
    "    def update_dict(self, state, dicttemp):\n",
    "        if state == 2:  # Checkbox checked state\n",
    "            for color in dicttemp[\"colour\"]:\n",
    "                self.stack_dict[\"colour\"][color] = dicttemp[\"colour\"][color]\n",
    "                dicttemp[\"colour\"][color] = 100\n",
    "            print(self.stack_dict)                \n",
    "                # WILL NEED TO SEND TO SPECIAL NODES LAYER\n",
    "\n",
    "    def clear_choices(self, dict, dicttemp):\n",
    "        self.checkbox.setChecked(False)\n",
    "        for dropdown in self.dropdowns:\n",
    "            dropdown.setCurrentIndex(0)  # Reset dropdown menu to \"None\"\n",
    "\n",
    "        for color in dict[\"colour\"]:\n",
    "            dict[\"colour\"][color] = 100  # Reset color values to 100\n",
    "            dicttemp[\"colour\"][color] = 100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    color_codes = {\n",
    "        'red': 1,\n",
    "        'green': 2,\n",
    "        'blue': 3,\n",
    "        'magenta': 4,\n",
    "        'cyan': 5\n",
    "    }\n",
    "    widget = ColorChannelWidget(color_codes)\n",
    "    widget.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QComboBox, QLabel, QCheckBox, QPushButton\n",
    "\n",
    "class ColorChannelWidget(QWidget):\n",
    "    def __init__(self, color_codes):\n",
    "        super().__init__()\n",
    "        self.color_codes = color_codes\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.dropdowns = []\n",
    "        self.checkboxes = []\n",
    "        self.stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "        self.temp_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for i in range(5):\n",
    "            channel_layout = QHBoxLayout()\n",
    "            label = QLabel(f\"Channel {i}:\")\n",
    "            dropdown = QComboBox()\n",
    "            dropdown.addItem(\"None\")\n",
    "            for color_code in self.color_codes.keys():\n",
    "                dropdown.addItem(color_code)\n",
    "            dropdown.currentIndexChanged.connect(lambda index, i=i, diction=self.temp_dict: self.handle_selection(index, i, diction))\n",
    "            channel_layout.addWidget(label)\n",
    "            channel_layout.addWidget(dropdown)\n",
    "            layout.addLayout(channel_layout)\n",
    "            self.dropdowns.append(dropdown)\n",
    "\n",
    "        # Create layout for Clear Choices button and Confirm Colour Selection checkbox\n",
    "        button_layout = QHBoxLayout()\n",
    "        \n",
    "        # Confirm checkbox\n",
    "        self.checkbox = QCheckBox(\"Confirm colour channel selection\")\n",
    "        self.checkbox.stateChanged.connect(lambda state,  diction=self.temp_dict: self.update_dict(state, diction))\n",
    "        button_layout.addWidget(self.checkbox)\n",
    "\n",
    "        # Clear button\n",
    "        self.clear_button = QPushButton(\"Clear Choices\")\n",
    "        self.clear_button.clicked.connect(lambda: self.clear_choices(self.stack_dict, self.temp_dict))\n",
    "        button_layout.addWidget(self.clear_button)\n",
    "\n",
    "        # Add button layout to the main layout\n",
    "        layout.addLayout(button_layout)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Color Channel Selector')\n",
    "\n",
    "    def handle_selection(self, index, channel_index, dicttemp):\n",
    "        if index != 0:\n",
    "            color_name = self.dropdowns[channel_index].currentText()\n",
    "            dicttemp[\"colour\"][color_name] = channel_index\n",
    "            # Uncheck the checkbox when a dropdown is changed\n",
    "            self.checkbox.setChecked(False)\n",
    "\n",
    "    def update_dict(self, state, dicttemp):\n",
    "        if state == 2:  # Checkbox checked state\n",
    "            for color in dicttemp[\"colour\"]:\n",
    "                self.stack_dict[\"colour\"][color] = dicttemp[\"colour\"][color]\n",
    "                dicttemp[\"colour\"][color] = 100\n",
    "                # WILL NEED TO SEND TO SPECIAL NODES LAYER\n",
    "\n",
    "    def clear_choices(self, dict, dicttemp):\n",
    "        self.checkbox.setChecked(False)\n",
    "        for dropdown in self.dropdowns:\n",
    "            dropdown.setCurrentIndex(0)  # Reset dropdown menu to \"None\"\n",
    "\n",
    "        for color in dict[\"colour\"]:\n",
    "            dict[\"colour\"][color] = 100  # Reset color values to 100\n",
    "            dicttemp[\"colour\"][color] = 100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    color_codes = {\n",
    "        'red': 1,\n",
    "        'green': 2,\n",
    "        'blue': 3,\n",
    "        'magenta': 4,\n",
    "        'cyan': 5\n",
    "    }\n",
    "    widget = ColorChannelWidget(color_codes)\n",
    "    widget.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QHBoxLayout, QComboBox, QLabel, QCheckBox, QPushButton\n",
    "\n",
    "class ColorChannelWidget(QWidget):\n",
    "    def __init__(self, color_codes):\n",
    "        super().__init__()\n",
    "        self.color_codes = color_codes\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.dropdowns = []\n",
    "        self.checkboxes = []\n",
    "        self.stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "        self.temp_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "\n",
    "        for i in range(5):\n",
    "            channel_layout = QHBoxLayout()\n",
    "            label = QLabel(f\"Channel {i}:\")\n",
    "            dropdown = QComboBox()\n",
    "            dropdown.addItem(\"None\")\n",
    "            for color_code in self.color_codes.keys():\n",
    "                dropdown.addItem(color_code)\n",
    "            dropdown.currentIndexChanged.connect(lambda index, i=i, diction=self.temp_dict: self.handle_selection(index, i, diction))\n",
    "            channel_layout.addWidget(label)\n",
    "            channel_layout.addWidget(dropdown)\n",
    "            layout.addLayout(channel_layout)\n",
    "            self.dropdowns.append(dropdown)\n",
    "\n",
    "        # Confirm checkbox\n",
    "        self.checkbox = QCheckBox(\"Confirm colour channel selection\")\n",
    "        self.checkbox.stateChanged.connect(lambda state,  diction=self.temp_dict: self.update_dict(state, diction))\n",
    "        layout.addWidget(self.checkbox)\n",
    "\n",
    "        # Clear button\n",
    "        self.clear_button = QPushButton(\"Clear Choices\")\n",
    "        self.clear_button.clicked.connect(lambda: self.clear_choices(self.stack_dict, self.temp_dict))\n",
    "        layout.addWidget(self.clear_button)\n",
    "\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Color Channel Selector')\n",
    "\n",
    "    def handle_selection(self, index, channel_index, dicttemp):\n",
    "        if index != 0:\n",
    "            color_name = self.dropdowns[channel_index].currentText()\n",
    "            dicttemp[\"colour\"][color_name] = channel_index\n",
    "            # Uncheck the checkbox when a dropdown is changed\n",
    "            self.checkbox.setChecked(False)\n",
    "\n",
    "    def update_dict(self, state, dicttemp):\n",
    "        if state == 2:  # Checkbox checked state\n",
    "            for color in dicttemp[\"colour\"]:\n",
    "                self.stack_dict[\"colour\"][color] = dicttemp[\"colour\"][color]\n",
    "                dicttemp[\"colour\"][color] = 100\n",
    "                # WILL NEED TO SEND TO SPECIAL NODES LAYER\n",
    "\n",
    "    def clear_choices(self, dict, dicttemp):\n",
    "        self.checkbox.setChecked(False)\n",
    "        for dropdown in self.dropdowns:\n",
    "            dropdown.setCurrentIndex(0)  # Reset dropdown menu to \"None\"\n",
    "\n",
    "        for color in dict[\"colour\"]:\n",
    "            dict[\"colour\"][color] = 100  # Reset color values to 100\n",
    "            dicttemp[\"colour\"][color] = 100\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    color_codes = {\n",
    "        'red': 1,\n",
    "        'green': 2,\n",
    "        'blue': 3,\n",
    "        'magenta': 4,\n",
    "        'cyan': 5\n",
    "    }\n",
    "    widget = ColorChannelWidget(color_codes)\n",
    "    widget.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QComboBox, QLabel, QCheckBox, QPushButton\n",
    "\n",
    "class ColorChannelWidget(QWidget):\n",
    "    def __init__(self, color_codes):\n",
    "        super().__init__()\n",
    "        self.color_codes = color_codes\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.dropdowns = []\n",
    "        self.checkboxes = []\n",
    "        self.stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "        self.temp_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 100,\n",
    "                \"magenta\": 100,\n",
    "                \"cyan\": 100\n",
    "            }\n",
    "        }\n",
    "       \n",
    "\n",
    "        for i in range(5):\n",
    "            label = QLabel(f\"Channel {i}:\")\n",
    "            dropdown = QComboBox()\n",
    "            dropdown.addItem(\"None\")\n",
    "            for color_code in self.color_codes.keys():\n",
    "                dropdown.addItem(color_code)\n",
    "            dropdown.currentIndexChanged.connect(lambda index, i=i, diction = self.temp_dict: self.handle_selection(index, i, diction))\n",
    "            layout.addWidget(label)\n",
    "            layout.addWidget(dropdown)\n",
    "            self.dropdowns.append(dropdown)\n",
    "\n",
    "        # Confrim checkbox\n",
    "        self.checkbox = QCheckBox(\"Confirm colour channel selection\")\n",
    "        self.checkbox.stateChanged.connect(lambda state,  diction = self.temp_dict : self.update_dict(state, diction))\n",
    "        layout.addWidget(self.checkbox)\n",
    "\n",
    "\n",
    "        self.clear_button = QPushButton(\"Clear Choices\")\n",
    "        self.clear_button.clicked.connect(lambda: self.clear_choices(self.stack_dict, self.temp_dict))\n",
    "        layout.addWidget(self.clear_button)\n",
    "\n",
    "        print(self.stack_dict)\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Color Channel Selector')\n",
    "\n",
    "    def handle_selection(self, index, channel_index, dicttemp):\n",
    "        if index != 0:\n",
    "            color_name =self.dropdowns[channel_index].currentText()\n",
    "            dicttemp[\"colour\"][color_name] = channel_index\n",
    "            print(f\"{color_name}: Channel {channel_index}\")\n",
    "            print(self.stack_dict)\n",
    "            # Uncheck the checkbox when a dropdown is changed\n",
    "            self.checkbox.setChecked(False)\n",
    "\n",
    "    def update_dict(self, state, dicttemp):\n",
    "        if state == 2:  # Checkbox checked state\n",
    "            for color in dicttemp[\"colour\"]:\n",
    "                self.stack_dict[\"colour\"][color] = dicttemp[\"colour\"][color]\n",
    "                dicttemp[\"colour\"][color] = 100\n",
    "                #WILL NEED TO SEND TO SPECIAL NODES LAYER\n",
    "            \n",
    "            print(\"Dictionary updated:\", self.stack_dict)\n",
    "            print(\"Dictionary temporary cleared:\", dicttemp)\n",
    "\n",
    "        \n",
    "    def clear_choices(self, dict, dicttemp):\n",
    "        self.checkbox.setChecked(False)\n",
    "        for dropdown in self.dropdowns:\n",
    "            dropdown.setCurrentIndex(0)  # Reset dropdown menu to \"None\"\n",
    "        \n",
    "        for color in dict[\"colour\"]:\n",
    "            dict[\"colour\"][color] = 100  # Reset color values to 100\n",
    "            dicttemp[\"colour\"][color] = 100\n",
    "        \n",
    "        print(\"Choices cleared and color values reset to 100:\", self.stack_dict)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    color_codes = {\n",
    "        'red': 1,\n",
    "        'green': 2,\n",
    "        'blue': 3,\n",
    "        'magenta': 4,\n",
    "        'cyan': 5\n",
    "    }\n",
    "    widget = ColorChannelWidget(color_codes)\n",
    "    widget.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QComboBox, QLabel\n",
    "\n",
    "class ColorChannelWidget(QWidget):\n",
    "    def __init__(self, color_codes):\n",
    "        super().__init__()\n",
    "        self.color_codes = color_codes\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        layout = QVBoxLayout()\n",
    "\n",
    "        self.dropdowns = []\n",
    "        self.stack_dict = {'time_step':0, 'red':100, 'green':100, 'blue':100, 'magenta':100, 'cyan':100 }\n",
    "\n",
    "        for i in range(5):\n",
    "            label = QLabel(f\"Channel {i}:\")\n",
    "            dropdown = QComboBox()\n",
    "            dropdown.addItem(\"None\")\n",
    "            for color_code in self.color_codes.keys():\n",
    "                dropdown.addItem(color_code)\n",
    "            dropdown.currentIndexChanged.connect(lambda index, i=i: self.handle_selection(index, i))\n",
    "            layout.addWidget(label)\n",
    "            layout.addWidget(dropdown)\n",
    "            self.dropdowns.append(dropdown)\n",
    "\n",
    "        print(self.stack_dict)\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Color Channel Selector')\n",
    "\n",
    "    def handle_selection(self, index, channel_index):\n",
    "        if index != 0:\n",
    "            color_name =self.dropdowns[channel_index].currentText()\n",
    "            self.stack_dict[color_name] = channel_index\n",
    "            print(f\"{color_name}: Channel {channel_index}\")\n",
    "            print(self.stack_dict)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app = QApplication(sys.argv)\n",
    "    color_codes = {\n",
    "        'red': 1,\n",
    "        'green': 2,\n",
    "        'blue': 3,\n",
    "        'magenta': 4,\n",
    "        'cyan': 5\n",
    "    }\n",
    "    widget = ColorChannelWidget(color_codes)\n",
    "    widget.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con2 experimenting different channels.\n",
    "\n",
    "Find shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Control_2.tif\"\n",
    "tif_file = tiff.TiffFile(path)\n",
    "image = tiff.imread(path)\n",
    "\n",
    "# metadata = tif_file.pages[0].tags\n",
    "# if metadata:\n",
    "#      # print(\"Metadata Tags:\")\n",
    "#     for tag_name, tag in metadata.items():\n",
    "#         print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "print(image.shape)\n",
    "\n",
    "# slice\n",
    "img = image[5, :, :, :]\n",
    "\n",
    "# original code\n",
    "# h, w, ch = img.shape\n",
    "# manipulate:\n",
    "# how to deal with this / generalize?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried with Numpy but didnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "\n",
    "path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Control_2.tif\"\n",
    "tif_file = tiff.TiffFile(path)\n",
    "image1 = tiff.imread(path)\n",
    "image = ((image1 / np.max(image1)) * 255).astype(np.uint8)\n",
    "\n",
    "print(image.shape)\n",
    "dim = [1, 15, 1024, 1024, 3]\n",
    "if image.shape[-3] <= 4:\n",
    "    print(\"Strange dimension\")\n",
    "    # If no time step data\n",
    "    if len(image.shape) == 4: \n",
    "        image = image[np.newaxis, :, :, :, :]\n",
    "\n",
    "    # Create an empty array with the specified dimensions\n",
    "    image_data_stacked = np.empty(dim, dtype=np.uint8)\n",
    "\n",
    "    num_time_frames = dim[0]  # Get the number of time frames\n",
    "    \n",
    "    # Reshape the image array to simplify stacking\n",
    "    reshaped_image = image.reshape(dim[0], dim[1], dim[2], dim[3], -1)\n",
    "\n",
    "    # Stack the channels along the last axis\n",
    "    image_data_stacked[:, :, :, :, :] = reshaped_image[:, :, :, :, :3]\n",
    "\n",
    "    print(image_data_stacked.shape)\n",
    "\n",
    "class Widget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "        try:\n",
    "            h, w, ch  = img.shape\n",
    "            bytes_per_line = ch * w \n",
    "            qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            \n",
    "            if qt_image is not None:\n",
    "                scale_factor = 0.7\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1.2\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Create an instance of the QApplication object\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = Widget()\n",
    "\n",
    "# Show the image in the widget\n",
    "widget.show_image(image_data_stacked[0, 9])\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting ZCXY To ZXYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Control_2.tif\"\n",
    "tif_file = tiff.TiffFile(path)\n",
    "image1 = tiff.imread(path)\n",
    "image = ((image1 / np.max(image1)) * 255).astype(np.uint8)\n",
    "print(image.shape)\n",
    "dim = [1, 15, 1024, 1024, 3]\n",
    "if image.shape[-3] <= 4:\n",
    "    print(\"Strange dimension\")\n",
    "    #if no time step data \n",
    "    if len(image.shape) ==4: \n",
    "        image = image[np.newaxis,:,:,:,:]\n",
    "\n",
    "    # Create an empty array with the specified dimensions\n",
    "    image_data_stacked = np.empty(dim, dtype=np.uint8)\n",
    "\n",
    "    num_time_frames = dim[0]  # Get the number of time frames\n",
    "    \n",
    "    for t in range(num_time_frames):  # Iterate over the time frames\n",
    "        for i in range(dim[1]):  # Iterate over the images in each time frame\n",
    "            # Get the red, green, and blue channels for the i-th image in the t-th time frame\n",
    "            print(i)\n",
    "            red_channel = image[t, i, 0, :, :]  # Assuming the first dimension is time frame, then image index\n",
    "            green_channel = image[t, i, 1, :, :]\n",
    "            blue_channel = image[t, i, 2, :, :]\n",
    "            \n",
    "            # Stack the channels along the last axis\n",
    "            image_data_stacked[t, i, :, :, 0] = red_channel\n",
    "            image_data_stacked[t, i, :, :, 1] = green_channel\n",
    "            image_data_stacked[t, i, :, :, 2] = blue_channel\n",
    "\n",
    "    print(image_data_stacked.shape)\n",
    "    \n",
    "#     print(\"strange dimension\")\n",
    "\n",
    "#     image_data_stacked = np.empty(dim[1:], dtype=np.uint8)\n",
    "#     print(dim[1:])\n",
    "#     # for y in range(dim[0]):\n",
    "#     for i in range(dim[1]):\n",
    "#             # Get the red, green, and blue channels for the i-th image\n",
    "#             red_channel = image[i, 0, :, :]\n",
    "#             green_channel = image[i, 1, :, :]\n",
    "#             blue_channel = image[i, 2, :, :]\n",
    "            \n",
    "#             # Stack the channels along the last axis\n",
    "#             image_data_stacked[i] = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "    \n",
    "\n",
    "# print(image_data_stacked.shape)\n",
    "\n",
    "class Widget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "        try:\n",
    "            h, w, ch  = img.shape\n",
    "            bytes_per_line = ch * w \n",
    "            # qt_image = QImage(img.data, w, h, QImage.Format_RGB888)Format_RGB16\n",
    "            qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            \n",
    "            if qt_image is not None:\n",
    "                scale_factor = 0.7\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1.2\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Create an instance of the QApplication object\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = Widget()\n",
    "\n",
    "# Show the image in the widget\n",
    "widget.show_image(image_data_stacked[0,9,:,:,:])\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle magenta\n",
    "\n",
    "Use numpy to optimize computation\n",
    "\n",
    "Just for the slice. Leave the individual channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_channels_RGB(self, img):\n",
    "        single_chan = img[:,:,0]\n",
    "        # Initialize RGB channels with zeros\n",
    "        red_channel = np.zeros_like(single_chan)\n",
    "        green_channel = np.zeros_like(single_chan)\n",
    "        blue_channel = np.zeros_like(single_chan)\n",
    "\n",
    "        \n",
    "        for color, channel_value in self.stack_dict[\"colour\"].items():\n",
    "                #RGB\n",
    "                if self.stack_dict[\"colour\"][\"red\"] != 100: \n",
    "                        red_channel = img[:,:,channel_value] \n",
    "                if self.stack_dict[\"colour\"][\"green\"] != 100: \n",
    "                        green_channel = img[:,:,channel_value] \n",
    "                if self.stack_dict[\"colour\"][\"blue\"] != 100: \n",
    "                        blue_channel = img[:,:,channel_value] \n",
    "                #CYM\n",
    "                if self.stack_dict[\"colour\"][\"cyan\"] != 100: \n",
    "                        cyan_channel = img[:,:,channel_value] \n",
    "                        green_channel = np.add(red_channel, cyan_channel)\n",
    "                        blue_channel = np.add(blue_channel, cyan_channel)\n",
    "                       \n",
    "\n",
    "                #repeat for yellow and magenta\n",
    "                        \n",
    "        # Clip values to ensure they remain within the valid range [0, 255]\n",
    "        red_channel = np.clip(red_channel, 0, 255)\n",
    "        green_channel = np.clip(green_channel, 0, 255)\n",
    "        blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "\n",
    "        # Combine channels back into image data\n",
    "        rgb_image_stack = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "                \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = r\"/home/emma/ve/vipp/SkripsieProject/skripsie_projects/Control_2.tif\"\n",
    "tif_file = tiff.TiffFile(path)\n",
    "image = tiff.imread(path)\n",
    "\n",
    "# metadata = tif_file.pages[0].tags\n",
    "# if metadata:\n",
    "#      # print(\"Metadata Tags:\")\n",
    "#     for tag_name, tag in metadata.items():\n",
    "#         print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "print(image.shape)\n",
    "print(np.max(image[9,0,:,:]))\n",
    "print(np.max(image[9,1,:,:]))\n",
    "print(np.max(image[9,2,:,:]))\n",
    "# Slice\n",
    "img = image[5, :, :, :]\n",
    "# Normlize for 8bit PyQt widget\n",
    "img_norm = ((img / np.max(img)) * 255).astype(np.uint8)\n",
    "\n",
    "print(\"img_norm\")\n",
    "print(img_norm.shape)\n",
    "\n",
    "# Extract individual channels\n",
    "magenta_channel = img_norm[0,:,:]\n",
    "green_channel = img_norm[1,:,:]\n",
    "blue_channel = img_norm[2,:,:]\n",
    "red_channel = np.zeros_like(blue_channel)\n",
    "\n",
    "# red_channel = img_norm[0,:,:]\n",
    "# green_channel = img_norm[1,:,:]\n",
    "# blue_channel = img_norm[2,:,:]\n",
    "\n",
    "# Add magenta channel to red and blue channels\n",
    "red_channel = np.add(red_channel, magenta_channel)\n",
    "blue_channel = np.add(blue_channel, magenta_channel)\n",
    "\n",
    "# Clip values to ensure they remain within the valid range [0, 255]\n",
    "red_channel = np.clip(red_channel, 0, 255)\n",
    "blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "# Combine channels back into image data\n",
    "rgb_image_stack = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "# # rgb_image = np.concatenate((red_channel, green_channel, blue_channel), axis=-1)\n",
    "# print(\"stack\")\n",
    "# print(rgb_image_stack.shape)\n",
    "\n",
    "# # print(np.max(rgb_image_stack[0,:,:]))\n",
    "# # print(np.max(rgb_image_stack[1,:,:]))\n",
    "# # print(np.max(rgb_image_stack[2,:,:]))\n",
    "\n",
    "\n",
    "\n",
    "# rgb_image_tansp = img_norm.reshape(1024,1024,3)\n",
    "# image_bytes = rgb_image_transp.tobytes()\n",
    "# rgb_image_tansp = np.transpose(img_norm, (1, 2, 0))\n",
    "# rgb_image_tansp = np.moveaxis(img_norm, 0, 2)\n",
    "print(np.max(rgb_image_stack[:,:, 0]))\n",
    "print(np.max(rgb_image_stack[:,:,1]))\n",
    "print(np.max(rgb_image_stack[:,:,2]))\n",
    "# rgb_image_tansp = rgb_image_stack\n",
    "print(\"transpose\")\n",
    "print(rgb_image_stack.shape)\n",
    "print(type(rgb_image_stack))\n",
    "# plt.imshow(rgb_image)\n",
    "# plt.axis('off')  # optional: turn off axis\n",
    "# plt.show()\n",
    "# print(rgb_image.shape)\n",
    "\n",
    "\n",
    "def assign_channels_RGB(img):\n",
    "    stack_dict = {\n",
    "            \"time_step\": 0,\n",
    "            \"colour\": {\n",
    "                \"red\": 100,\n",
    "                \"green\": 100,\n",
    "                \"blue\": 1,\n",
    "                \"cyan\": 100,\n",
    "                \"yellow\": 2,\n",
    "                \"magenta\": 0\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    \n",
    "    single_chan = img[:, :, 0]\n",
    "    # Initialize RGB channels with zeros\n",
    "    red_channel = np.zeros_like(single_chan)\n",
    "    green_channel = np.zeros_like(single_chan)\n",
    "    blue_channel = np.zeros_like(single_chan)\n",
    "\n",
    "    for color, channel_value in stack_dict[\"colour\"].items():\n",
    "        # Check if the channel is part of the image\n",
    "        if channel_value != 100:\n",
    "            # Assign channels based on the color\n",
    "            if color == \"red\":\n",
    "                red_channel += img[:, :, channel_value]\n",
    "            elif color == \"green\":\n",
    "                green_channel += img[:, :, channel_value]\n",
    "            elif color == \"blue\":\n",
    "                blue_channel += img[:, :, channel_value]\n",
    "            elif color == \"cyan\":\n",
    "                cyan_channel = img[:, :, channel_value]\n",
    "                green_channel += cyan_channel\n",
    "                blue_channel += cyan_channel\n",
    "            elif color == \"magenta\":\n",
    "                magenta_channel = img[:, :, channel_value]\n",
    "                red_channel += magenta_channel\n",
    "                blue_channel += magenta_channel\n",
    "            elif color == \"yellow\":\n",
    "                yellow_channel = img[:, :, channel_value]\n",
    "                red_channel += yellow_channel\n",
    "                green_channel += yellow_channel\n",
    "\n",
    "    # Clip values to ensure they remain within the valid range [0, 255]\n",
    "    red_channel = np.clip(red_channel, 0, 255)\n",
    "    green_channel = np.clip(green_channel, 0, 255)\n",
    "    blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "    # Combine channels back into image data\n",
    "    rgb_image_stack = np.stack([red_channel, green_channel, blue_channel], axis=2)\n",
    "\n",
    "    return rgb_image_stack\n",
    "\n",
    "class Widget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "        try:\n",
    "            h, w, ch  = img.shape\n",
    "            bytes_per_line = ch * w \n",
    "            # qt_image = QImage(img.data, w, h, QImage.Format_RGB888)Format_RGB16\n",
    "            qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            \n",
    "            if qt_image is not None:\n",
    "                scale_factor = 0.7\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1.2\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Create an instance of the QApplication object\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = Widget()\n",
    "\n",
    "# Show the image in the widget\n",
    "rgb_assigned = assign_channels_RGB(rgb_image_stack)\n",
    "widget.show_image(rgb_assigned)\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual channels\n",
    "magenta_channel = img[0]\n",
    "red_channel = img[1]\n",
    "blue_channel = img[2]\n",
    "\n",
    "# Add magenta channel to red and blue channels\n",
    "red_channel = np.add(red_channel, magenta_channel)\n",
    "blue_channel = np.add(blue_channel, magenta_channel)\n",
    "\n",
    "# Clip values to ensure they remain within the valid range [0, 255]\n",
    "red_channel = np.clip(red_channel, 0, 255)\n",
    "blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "# Combine channels back into image data\n",
    "rgb_image = np.stack([red_channel, np.zeros_like(red_channel), blue_channel])\n",
    "print(rgb_image.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Normlize for 8bit PyQt widget\n",
    "rgb_image = (rgb_image / np.max(img) * 255).astype(np.uint8)\n",
    "print(rgb_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual channels\n",
    "magenta_channel = image[0, :, :, :]\n",
    "red_channel = image[1, :, :, :]\n",
    "blue_channel = image[2,  :, :, :]\n",
    "\n",
    "# Add magenta channel to red and blue channels\n",
    "red_channel = np.add(red_channel, magenta_channel)\n",
    "blue_channel = np.add(blue_channel, magenta_channel)\n",
    "\n",
    "# Clip values to ensure they remain within the valid range [0, 255]\n",
    "red_channel = np.clip(red_channel, 0, 255)\n",
    "blue_channel = np.clip(blue_channel, 0, 255)\n",
    "\n",
    "# Combine channels back into image data\n",
    "image_data_processed = np.stack([magenta_channel, red_channel, blue_channel])\n",
    "np.concatenate((self.red_stack, self.gr_stack, self.blue_stack), axis=-1)\n",
    "print(image.shape)\n",
    "# slice,\n",
    "img = image_data_processed[10, :, :, :]\n",
    "\n",
    "# Normlize for 8bit PyQt widget\n",
    "img = (img / np.max(img) * 255).astype(np.uint8)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "import numpy as np\n",
    "\n",
    "class YourWidget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "        try:\n",
    "            ch, h, w = img.shape\n",
    "            bytes_per_line = ch * w\n",
    "            qt_image = QImage(img.data, w, h, QImage.Format_RGB888)\n",
    "            \n",
    "            if qt_image is not None:\n",
    "                scale_factor = 0.7\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1.2\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Create an instance of the QApplication object\n",
    "app = QApplication(sys.argv)\n",
    "\n",
    "# Read the image\n",
    "# Assuming you have your image data in 'image_data'\n",
    "# image_data = np.random.rand(3, 1024, 1024)  # Example random image data\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = YourWidget()\n",
    "\n",
    "# Show the image in the widget\n",
    "widget.show_image(rgb_image)\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flybrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "\n",
    "path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\flybrain.tif\"\n",
    "tif_file = tiff.TiffFile(path)\n",
    "image = tiff.imread(path)\n",
    "\n",
    "metadata = tif_file.pages[0].tags\n",
    "if metadata:\n",
    "     # print(\"Metadata Tags:\")\n",
    "    for tag_name, tag in metadata.items():\n",
    "        print(f\"{tag_name}: {tag.value}\")\n",
    "\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "import tifffile as tiff\n",
    "\n",
    "class YourWidget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "        try:\n",
    "            qt_image = QImage(img.data, img.shape[1], img.shape[0], img.shape[1] * img.shape[2], QImage.Format_RGB888)\n",
    "            \n",
    "            if qt_image is not None:\n",
    "                scale_factor = 0.7\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1.2\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Read the image\n",
    "path = r\"C:\\Users\\dell\\OneDrive\\Documents\\Em\\2023\\Skripsie\\Development\\Data\\Control_2.tif\"\n",
    "image = tiff.imread(path)\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = YourWidget()\n",
    "\n",
    "# Show the image in the widget\n",
    "widget.show_image(image)\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QVBoxLayout, QLabel, QMessageBox\n",
    "from PyQt5.QtGui import QPixmap, QImage\n",
    "\n",
    "class YourWidget(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create a QLabel to display the image\n",
    "        self.image_label = QLabel(self)\n",
    "        \n",
    "        # Create a layout to arrange the widgets\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.image_label)\n",
    "        self.setLayout(layout)\n",
    "    \n",
    "    def show_image(self, img):\n",
    "        try:\n",
    "            if img.shape[-1] == 1:\n",
    "                qt_image = QImage(img.data, img.shape[1], img.shape[0], img.shape[1], QImage.Format_Grayscale8)\n",
    "            elif img.shape[-1] == 3:\n",
    "                h, w, ch = img.shape\n",
    "                bytes_per_line = ch * w\n",
    "                qt_image = QImage(img.data, w, h, bytes_per_line, QImage.Format_RGB888)\n",
    "            elif img.shape[-1] == 4:\n",
    "                h, w, ch = img.shape\n",
    "                bytes_per_line = ch * 4\n",
    "                qt_image = QImage(img.data, w, h, QImage.Format_RGBA8888)\n",
    "            \n",
    "            if qt_image is not None:\n",
    "                scale_factor = 0.7\n",
    "                if qt_image.width() < 400:\n",
    "                    scale_factor = 1.2\n",
    "                if qt_image.width() > 900:\n",
    "                    scale_factor = 0.5\n",
    "                target_width = int(qt_image.width() * scale_factor)\n",
    "                scaled_pixmap = QPixmap.fromImage(qt_image).scaledToWidth(target_width)\n",
    "                \n",
    "                self.image_label.setPixmap(scaled_pixmap)\n",
    "                self.resize(scaled_pixmap.width(), scaled_pixmap.height())\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# Create a function to display the pop-up window\n",
    "def show_popup():\n",
    "    popup = QMessageBox()\n",
    "    popup.setWindowTitle(\"Pop-up Window\")\n",
    "    popup.setText(\"Your message goes here!\")\n",
    "    popup.exec_()\n",
    "\n",
    "# Create an instance of the widget\n",
    "widget = YourWidget()\n",
    "\n",
    "# Show the pop-up window\n",
    "show_popup()\n",
    "\n",
    "# Read the image and display it\n",
    "image_data = read_tiff_image()  # Replace this with your function to read the TIFF image\n",
    "widget.show_image(image_data)\n",
    "\n",
    "# Display the widget\n",
    "widget.show()\n",
    "\n",
    "# Run the application\n",
    "sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sk_env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
